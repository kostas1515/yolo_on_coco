{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "import cv2\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='labels/coco2017labels.zip'\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "#     bbox=zip.read('coco/labels/train2017/000000371735.txt')\n",
    "#     box=(bbox.decode(\"utf-8\"))\n",
    "#     box=pd.DataFrame([x.split() for x in box.rstrip('\\n').split('\\n')],columns=['class','xc','yc','w','h'])\n",
    "#     print(box)\n",
    "    count = len(zip.infolist())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "file_name='labels/coco2017labels.zip'\n",
    "zip_file = ZipFile(file_name)\n",
    "\n",
    "dfs = {text_file.filename: pd.read_csv(zip_file.open(text_file.filename))\n",
    "       for text_file in zip_file.infolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a=torch.tensor([[[1,2,2,4,0,0,0,1],[2,3,5,3,0,0,1,0]]])\n",
    "print(a.shape)\n",
    "b=((a[:,:,4:]==1).nonzero())\n",
    "b=b[:,-1].unsqueeze(0).unsqueeze(-1)\n",
    "print(b.shape)\n",
    "new=a[:,:,:4]\n",
    "print(new.shape)\n",
    "new=torch.cat((new.T,b.T)).T\n",
    "print(new)\n",
    "sorted_pred=torch.sort(new[0,:,4],descending=False)\n",
    "print(sorted_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = box.values.astype(np.float32)\n",
    "b=torch.tensor(b)\n",
    "labels = b.T[0].reshape(b.shape[0], 1)\n",
    "one_hot_target = (labels == torch.arange(80).reshape(1, 80)).float()\n",
    "conf=torch.ones([b.shape[0],1])\n",
    "boxes=torch.cat((b.T[1:],conf.T,one_hot_target.T)).T\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='images/train2017.zip'\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    image=zip.read('train2017/000000408542.jpg')\n",
    "    img = cv2.imdecode(np.frombuffer(image, np.uint8),1)\n",
    "    im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    io.imshow(im_rgb)\n",
    "    io.imsave('fig.png',im_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('pointers/train2017.txt',names=['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['box']=df['filename'].apply(lambda x: 'coco/labels/'+x.split('.')[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Length of dataset is 118287\n",
      "\n",
      "\n",
      " epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/konsa15/.conda/envs/faster_rcnn/lib/python3.8/site-packages/torch/nn/functional.py:2503: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\"Default upsampling behavior when mode={} is changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pgr:0.7574796892304311% L:11.549149513244629 IoU:0.6676708459854126 pob:0.18707382678985596 nob:0.0013496415922418237 PCls:0.6157740354537964 ncls:0.00486361980438232463"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/users/konsa15/.conda/envs/faster_rcnn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-ec7dbd2f8718>\", line 187, in <module>\n",
      "    torch.cuda.empty_cache()\n",
      "  File \"/users/konsa15/.conda/envs/faster_rcnn/lib/python3.8/site-packages/torch/cuda/memory.py\", line 35, in empty_cache\n",
      "    torch._C._cuda_emptyCache()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/konsa15/.conda/envs/faster_rcnn/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/users/konsa15/.conda/envs/faster_rcnn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/users/konsa15/.conda/envs/faster_rcnn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/users/konsa15/.conda/envs/faster_rcnn/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/users/konsa15/.conda/envs/faster_rcnn/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/users/konsa15/.conda/envs/faster_rcnn/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/users/konsa15/.conda/envs/faster_rcnn/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/users/konsa15/.conda/envs/faster_rcnn/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/users/konsa15/.conda/envs/faster_rcnn/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/users/konsa15/.conda/envs/faster_rcnn/lib/python3.8/posixpath.py\", line 425, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/users/konsa15/.conda/envs/faster_rcnn/lib/python3.8/posixpath.py\", line 167, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "from dataset import *\n",
    "import timeit \n",
    "import skimage.io as io\n",
    "import cv2\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import timeit\n",
    "import torch.autograd\n",
    "import helper as helper\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "net = Darknet(\"../cfg/yolov3.cfg\")\n",
    "inp_dim=net.inp_dim\n",
    "pw_ph=net.pw_ph.to(device='cuda')\n",
    "cx_cy=net.cx_cy.to(device='cuda')\n",
    "stride=net.stride.to(device='cuda')\n",
    "\n",
    "\n",
    "'''\n",
    "when loading weights from dataparallel model then, you first need to instatiate the dataparallel model \n",
    "if you start fresh then first model.load_weights and then make it parallel\n",
    "'''\n",
    "try:\n",
    "    PATH = '../mse.pth'\n",
    "    weights = torch.load(PATH)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we https://pytorch.org/docs/stable/data.html#torch.utils.data.Datasetare on a CUDA machine, this should print a CUDA device:\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "\n",
    "    if torch.cuda.device_count() > 9:\n",
    "        print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(net)\n",
    "        model.to(device)\n",
    "        model.load_state_dict(weights)\n",
    "    else:\n",
    "        model=net\n",
    "        model.to(device)\n",
    "        model.load_state_dict(weights)\n",
    "        \n",
    "except FileNotFoundError: \n",
    "#     net.load_weights(\"yolov3.weights\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(net)\n",
    "        model.to(device)\n",
    "    else:\n",
    "        model=net\n",
    "        \n",
    "        \n",
    "transformed_dataset=Coco(partition='train',\n",
    "                                           transform=transforms.Compose([\n",
    "                                            ResizeToTensor(inp_dim)\n",
    "                                           ]))\n",
    "\n",
    "\n",
    "writer = SummaryWriter('../results/test')\n",
    "dataset_len=(len(transformed_dataset))\n",
    "print('Length of dataset is '+ str(dataset_len)+'\\n')\n",
    "batch_size=8\n",
    "\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=batch_size,\n",
    "                        shuffle=False,collate_fn=helper.my_collate, num_workers=2)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, weight_decay=0.0005, momentum=0.9)\n",
    "epochs=50\n",
    "total_loss=0\n",
    "write=0\n",
    "misses=0\n",
    "break_flag=0\n",
    "avg_iou=0\n",
    "for e in range(epochs):\n",
    "    prg_counter=0\n",
    "    train_counter=0\n",
    "    total_loss=0\n",
    "    avg_iou=0\n",
    "    avg_infs=0\n",
    "    avg_conf=0\n",
    "    avg_no_conf=0\n",
    "    avg_pos=0\n",
    "    avg_neg=0\n",
    "    print(\"\\n epoch \"+str(e))\n",
    "    misses=0\n",
    "    for images,targets,img_names in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        targets,anchors,offset,strd,mask=helper.collapse_boxes(targets,pw_ph,cx_cy,stride)\n",
    "        images=images.cuda()\n",
    "        raw_pred = model(images, torch.cuda.is_available())\n",
    "        raw_pred=helper.expand_predictions(raw_pred,mask)\n",
    "        true_pred=util.transform(raw_pred.clone(),anchors,offset,strd)\n",
    "        targets=targets.unsqueeze(-3)\n",
    "        targets=targets.cuda()\n",
    "        iou_mask,noobj_mask=util.get_responsible_masks(true_pred,targets,offset,strd,mask,inp_dim)\n",
    "        \n",
    "        iou1=torch.diag(util.bbox_iou(util.get_abs_coord(true_pred[iou_mask.T,:].unsqueeze(-3)),util.transpose_target(get_abs_coord(targets)*inp_dim)))\n",
    "        iou=iou1.mean().item()\n",
    "        noobj_box=raw_pred[:,:,4:5].clone()\n",
    "        noobj_box=helper.uncollapse(noobj_box,mask)\n",
    "        noobj_mask=helper.uncollapse(noobj_mask.T.unsqueeze(-1),mask)\n",
    "        \n",
    "        \n",
    "        conf=raw_pred[iou_mask.T,:][:,4:5].mean().item()\n",
    "        class_mask=targets[:,:,5:].type(torch.BoolTensor).squeeze(0)\n",
    "        if(iou_mask.sum()==class_mask.shape[0]):\n",
    "            pos_class=raw_pred[iou_mask.T,:][:,5:][class_mask].mean().item()\n",
    "            neg_class=raw_pred[iou_mask.T,:][:,5:][~class_mask].mean().item()\n",
    "        else:\n",
    "            pos_class=0\n",
    "            neg_class=0\n",
    "        noobj_box=noobj_box[noobj_mask]\n",
    "        no_obj_conf=noobj_box.mean().item()\n",
    "        \n",
    "        raw_pred=raw_pred[iou_mask.T,:]\n",
    "        anchors=anchors[iou_mask.T,:]\n",
    "        offset=offset[iou_mask.T,:]\n",
    "        strd=strd[iou_mask.T,:]\n",
    "        if(strd.shape[0]==sum(mask)):#this means that iou_mask failed and was all true, because max of zeros is true for all lenght of mask strd\n",
    "            targets[:,:,0:4]=targets[:,:,0:4]*inp_dim\n",
    "            targets=targets.squeeze(0)\n",
    "            targets[:,0:4]=util.transform_groundtruth(targets,anchors,offset,strd)\n",
    "            with torch.autograd.set_detect_anomaly(True):\n",
    "                loss=util.yolo_loss(raw_pred,targets,noobj_box,mask)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            avg_conf=avg_conf+conf\n",
    "            avg_no_conf=avg_no_conf+no_obj_conf\n",
    "            avg_pos=avg_pos+pos_class\n",
    "            avg_neg=avg_neg+neg_class\n",
    "            total_loss=total_loss+loss.item()\n",
    "            avg_iou=avg_iou+iou\n",
    "            sys.stdout.write('\\rPgr:'+str(prg_counter/dataset_len*100*batch_size)+'%' ' L:'+ str(loss.item()))\n",
    "            sys.stdout.write(' IoU:' +str(iou)+' pob:'+str(conf)+ ' nob:'+str(no_obj_conf))\n",
    "            sys.stdout.write(' PCls:' +str(pos_class)+' ncls:'+str(neg_class))\n",
    "            sys.stdout.flush()\n",
    "            prg_counter=prg_counter+1\n",
    "            train_counter=train_counter+1\n",
    "        else:\n",
    "            print('missed')\n",
    "            print(strd.shape[0])\n",
    "            prg_counter=prg_counter+1\n",
    "        iou1=iou1.tolist()\n",
    "        iou_per_class= [0] * 80\n",
    "        averager_per_class=[1] * 80\n",
    "        for i,el in enumerate(iou1):\n",
    "            name=targets[i,5:].max(0)[1].cpu().detach().numpy()\n",
    "            iou_per_class[name]=iou_per_class[name]+el\n",
    "            averager_per_class[name]=averager_per_class[name]+1\n",
    "        for i in range(80):\n",
    "            if (iou_per_class[i]!=0):\n",
    "                if i<40:\n",
    "                    writer.add_scalar('Iou0/'+str(i), iou_per_class[i]/averager_per_class[i], train_counter)\n",
    "                else:\n",
    "                    writer.add_scalar('Iou1/'+str(i), iou_per_class[i]/averager_per_class[i], train_counter)\n",
    "        writer.add_scalar('AvLoss/train', total_loss/train_counter, train_counter)\n",
    "\n",
    "        \n",
    "        writer.add_scalar('AvIoU/train', avg_iou/train_counter, train_counter)\n",
    "\n",
    "        writer.add_scalar('AvPConf/train', avg_conf/train_counter, train_counter)\n",
    "        \n",
    "        writer.add_scalar('AvNConf/train', avg_no_conf/train_counter, train_counter)\n",
    "        \n",
    "        writer.add_scalar('AvClass/train', avg_pos/train_counter, train_counter)\n",
    "        \n",
    "        writer.add_scalar('AvNClass/train', avg_neg/train_counter, train_counter)\n",
    "        \n",
    "        del loss, raw_pred, targets, true_pred, images,iou,noobj_box,conf,iou1\n",
    "        torch.cuda.empty_cache()\n",
    "    if misses>0:\n",
    "        break\n",
    "#     torch.save(model.state_dict(), PATH)\n",
    "#     writer.add_scalar('Loss/train', total_loss/train_counter, e)\n",
    "#     writer.add_scalar('AIoU/train', avg_iou/train_counter, e)\n",
    "#     writer.add_scalar('PConf/train', avg_conf/train_counter, e)\n",
    "#     writer.add_scalar('NConf/train', avg_no_conf/train_counter, e)\n",
    "#     writer.add_scalar('PClass/train', avg_pos/train_counter, e)\n",
    "#     writer.add_scalar('NClass/train', avg_neg/train_counter, e)\n",
    "    print('\\ntotal number of misses is ' + str(misses))\n",
    "    print('\\n total average loss is '+str(total_loss/train_counter))\n",
    "    print('\\n total average iou is '+str(avg_iou/train_counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 8])\n",
      "tensor([[[2.6762e-01, 4.9017e-03, 7.2748e-01],\n",
      "         [4.7385e-02, 8.6788e-04, 9.5175e-01]]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[[1,2,3,4,0.0,0,-4,1],[1,2,3,4,0.0,0,-4,3]]])\n",
    "\n",
    "print(a.shape)\n",
    "print(torch.softmax(a[:,:,5:],dim = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets2,anchors,offset,strd,mask=helper.collapse_boxes(targets,pw_ph,cx_cy,stride)\n",
    "transformed_output=true_pred\n",
    "targets=targets\n",
    "offset=offset\n",
    "strd=strd\n",
    "mask=mask\n",
    "inp_dim\n",
    "'''\n",
    "this function takes the transformed_output and\n",
    "the target box in respect to the resized image size\n",
    "and returns a mask which can be applied to select the \n",
    "best raw input,anchors and cx_cy_offset\n",
    "and the noobj_mask for the negatives\n",
    "targets is a list\n",
    "'''\n",
    "#first transpose the centered normalised target coords\n",
    "centered_target=transpose_target(targets)[:,:,0:2]\n",
    "#multiply by inp_dim then devide by stride to get the relative grid size coordinates, floor the result to get the corresponding cell\n",
    "centered_target=torch.floor(centered_target*inp_dim/strd)\n",
    "#create a mask to find where the gt falls into which gridcell in the grid coordinate system\n",
    "fall_into_mask=centered_target==offset\n",
    "fall_into_mask=fall_into_mask[:,:,0]&fall_into_mask[:,:,1]\n",
    "#     fall_into_mask= ~fall_into_mask\n",
    "#create a copy of the transformed output\n",
    "best_bboxes=transformed_output.clone()\n",
    "#apply reverse mask to copy in order to zero all other bbox locations\n",
    "best_bboxes[~fall_into_mask]=0   \n",
    "#transform the copy to xmin,xmax,ymin,ymax\n",
    "best_responsible_coord=get_abs_coord(best_bboxes)\n",
    "targets=transpose_target(get_abs_coord(targets))*inp_dim\n",
    "#calculate best iou and mask\n",
    "responsible_iou=bbox_iou(best_responsible_coord,targets,True)\n",
    "\n",
    "responsible_iou[responsible_iou.ne(responsible_iou)] = 0\n",
    "responsible_mask=responsible_iou.max(dim=0)[0] == responsible_iou\n",
    "\n",
    "print(responsible_mask.shape)\n",
    "\n",
    "abs_coord=get_abs_coord(transformed_output)\n",
    "iou=bbox_iou(abs_coord,targets,True)\n",
    "iou[iou.ne(iou)] = 0\n",
    "ignore_mask=0.5<=iou\n",
    "inverted_mask=iou.max(dim=0)[0] != iou\n",
    "noobj_mask=~same_picture_mask(responsible_mask.clone()|ignore_mask,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(responsible_mask)\n",
    "if(responsible_mask.sum()>sum(mask)):\n",
    "    print('jello')\n",
    "    responsible_mask1=correct_iou_mask(responsible_mask,fall_into_mask)\n",
    "print(responsible_mask1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.randint(0, 9, (1,)) == torch.arange(9)\n",
    "a=a.repeat(5)\n",
    "a=a.repeat(2,1)\n",
    "print(a)\n",
    "print(a.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_mask=(responsible_mask.sum(axis=0)==responsible_mask.sum(axis=0).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responsible_mask[:,le_mask]=(responsible_mask[:,le_mask]&fall_into_mask[le_mask,:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(le_mask)\n",
    "print(fall_into_mask[le_mask,:].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([1,2,3,4,5,6,6,6])\n",
    "indices=(((a==a.max())==True).nonzero())\n",
    "for ind in indices:\n",
    "    print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "testing with ../mse_mean_softmax.pth\n",
      "\n",
      "Length of dataset is 5000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/konsa15/.conda/envs/faster_rcnn/lib/python3.8/site-packages/torch/nn/functional.py:2503: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\"Default upsampling behavior when mode={} is changed \"\n"
     ]
    }
   ],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import timeit\n",
    "from dataset import *\n",
    "import torchvision.ops.boxes as nms_box\n",
    "import helper as helper\n",
    "from utils import *\n",
    "from BoundingBox import BoundingBox\n",
    "from BoundingBoxes import BoundingBoxes\n",
    "\n",
    "\n",
    "net = Darknet(\"../cfg/yolov3.cfg\")\n",
    "inp_dim=net.inp_dim\n",
    "pw_ph=net.pw_ph\n",
    "cx_cy=net.cx_cy\n",
    "stride=net.stride\n",
    "\n",
    "\n",
    "'''\n",
    "when loading weights from dataparallel model then, you first need to instatiate the dataparallel model \n",
    "if you start fresh then first model.load_weights and then make it parallel\n",
    "'''\n",
    "try:\n",
    "    PATH = '../mse_mean_softmax.pth'\n",
    "    weights = torch.load(PATH)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "\n",
    "    if torch.cuda.device_count() > 9:\n",
    "        print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(net)\n",
    "    else:\n",
    "        model=net\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(weights)\n",
    "    model.eval()\n",
    "except FileNotFoundError: \n",
    "    net.load_weights(\"../yolov3.weights\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "      print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "      model = nn.DataParallel(net)\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('testing with '+ PATH +'\\n')\n",
    "transformed_dataset=Coco(partition='val',\n",
    "                                           transform=transforms.Compose([\n",
    "                                            ResizeToTensor(inp_dim)\n",
    "                                           ]))\n",
    "\n",
    "\n",
    "\n",
    "dataset_len=(len(transformed_dataset))\n",
    "print('Length of dataset is '+ str(dataset_len)+'\\n')\n",
    "batch_size=8\n",
    "\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=batch_size,\n",
    "                        shuffle=True,collate_fn=helper.my_collate, num_workers=2)\n",
    "\n",
    "true_pos=0\n",
    "false_pos=0\n",
    "counter=0\n",
    "iou_threshold=0.5\n",
    "confidence=0.9\n",
    "recall_counter=0\n",
    "\n",
    "for images,targets,img_name in dataloader:\n",
    "    inp=images.cuda()\n",
    "    raw_pred = model(inp, torch.cuda.is_available())\n",
    "    targets,anchors,offset,strd,mask=helper.collapse_boxes(targets,pw_ph,cx_cy,stride)\n",
    "    raw_pred=raw_pred.to(device='cuda')\n",
    "    true_pred=util.transform(raw_pred.clone(),pw_ph,cx_cy,stride)\n",
    "    \n",
    "    sorted_pred=torch.sort(true_pred[:,:,4],descending=True)\n",
    "    pred_mask=sorted_pred[0]>confidence\n",
    "    indices=[(sorted_pred[1][e,:][pred_mask[e,:]]) for e in range(pred_mask.shape[0])]\n",
    "    pred_final=[true_pred[i,indices[i],:] for i in range(len(indices))]\n",
    "    \n",
    "    pred_final_coord=[util.get_abs_coord(pred_final[i].unsqueeze(-2)) for i in range(len(pred_final))]\n",
    "    \n",
    "    indices=[nms_box.nms(pred_final_coord[i][0],pred_final[i][:,4],iou_threshold) for i in range(len(pred_final))]\n",
    "\n",
    "    pred_final=[pred_final[i][indices[i],:] for i in range(len(pred_final))]\n",
    "#     pred_final[:,0:4]=pred_final[:,0:4]/inp_dim\n",
    "    helper.write_pred(img_name,pred_final,inp_dim)\n",
    "    \n",
    "\n",
    "    \n",
    "# Read txt files containing bounding boxes (ground truth and detections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import timeit\n",
    "from dataset import *\n",
    "import torchvision.ops.boxes as nms_box\n",
    "import helper as helper\n",
    "from utils import *\n",
    "from BoundingBox import BoundingBox\n",
    "from BoundingBoxes import BoundingBoxes\n",
    "boundingboxes = helper.getBoundingBoxes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COCO map is: 0.22513550608462682\n",
      "\n",
      "COCO map is: 0.4445726585907471\n",
      "\n",
      "COCO map is: 0.6593207072864868\n",
      "\n",
      "COCO map is: 0.8689802531917017\n",
      "\n",
      "COCO map is: 1.07306153820468\n",
      "\n",
      "COCO map is: 1.2711825540568698\n",
      "\n",
      "COCO map is: 1.4618880350267\n",
      "\n",
      "COCO map is: 1.6431973425913293\n",
      "\n",
      "COCO map is: 1.812508168901606\n",
      "\n",
      "COCO map is: 1.9673989271618426\n",
      "\n",
      "COCO map is: 2.1057099041538065\n",
      "\n",
      "COCO map is: 2.223252050948119\n",
      "\n",
      "COCO map is: 2.3146544011059556\n",
      "\n",
      "COCO map is: 2.3779222107723013\n",
      "\n",
      "COCO map is: 2.4188737800706868\n",
      "\n",
      "COCO map is: 2.43784946444538\n",
      "\n",
      "COCO map is: 2.444466275742045\n",
      "\n",
      "COCO map is: 2.446022532458621\n",
      "\n",
      "COCO map is: 2.446177751130332\n"
     ]
    }
   ],
   "source": [
    "from Evaluator import *\n",
    "from utils import *\n",
    "from BoundingBox import BoundingBox\n",
    "from BoundingBoxes import BoundingBoxes\n",
    "\n",
    "\n",
    "boundingboxes = helper.getBoundingBoxes()\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "iou=0.05\n",
    "MMap=0\n",
    "while iou<1:\n",
    "    metricsPerClass = evaluator.GetPascalVOCMetrics(boundingboxes, IOUThreshold=iou)\n",
    "#     print(\"Average precision values per class:\\n\")\n",
    "    # Loop through classes to obtain their metrics\n",
    "    mAP=0\n",
    "    counter=0\n",
    "    for mc in metricsPerClass:\n",
    "        # Get metric values per each class\n",
    "        c = mc['class']\n",
    "        precision = mc['precision']\n",
    "        recall = mc['recall']\n",
    "        average_precision = mc['AP']\n",
    "        ipre = mc['interpolated precision']\n",
    "        irec = mc['interpolated recall']\n",
    "        # Print AP per class\n",
    "        mAP=average_precision+mAP\n",
    "#         print('%s: %f' % (c, average_precision))\n",
    "    MMap=MMap+mAP/80\n",
    "    iou=iou+0.05\n",
    "    print('\\nCOCO map is:',MMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1882197449470953\n"
     ]
    }
   ],
   "source": [
    "print(MMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6020778bb0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD4CAYAAAAEhuazAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXzU1b3/8dcnk30hIRsIhE0CAmpFA+JOVZDaKtXaFq2ta+0i3bT12p+36rW97b3X3u70WlqVWqtobbVUqbhr3SCRfREIASQLJCEQsiczc35/JGIIgQzJJJOZeT8fjzyY7/d75pvPmRk+c3LO93uOOecQEZHoEhPqAEREZOAp+YuIRCElfxGRKKTkLyIShZT8RUSiUGyofnF2drYbO3ZsqH69iEhYeu+996qdczl9PU/Ikv/YsWMpKioK1a8XEQlLZrYrGOdRt4+ISBRS8hcRiUJK/iIiUUjJX0QkCin5i4hEoR6Tv5k9ZGaVZrbhKMfNzH5lZsVmts7MTg9+mCIiEkyBtPwXA3OPcfwTQH7Hzy3A//U9LBER6U89Jn/n3BtAzTGKzAMece3eBTLM7IRgBdhV4c4afvbCFlq9/v76FSIiES8Yff4jgd2dtks79h3BzG4xsyIzK6qqqurVL1u1az+/eqUYr1/JX0Skt4KR/K2bfd2uEOOcW+ScK3DOFeTk9PnuZBER6aVgJP9SIK/T9iigPAjnFRGRfhKM5L8U+FLHVT8zgVrnXEUQzisiIv2kx4ndzOxxYBaQbWalwD1AHIBz7gFgGXApUAw0Ajf0V7AiIhIcPSZ/59zVPRx3wK1Bi0hERPqd7vAVEYlCSv4iIlFIyV9EJAop+YuIRCElfxGRKKTkLyIShZT8RUSikJK/iEgUUvIXEYlCSv4iIlFIyV9EJAop+YuIRCElfxGRKKTkLyIShZT8RUSikJK/iEgUCij5m9lcM9tiZsVmdmc3x8eY2ctmts7MXjOzUcEPVUREgqXH5G9mHmAh8AlgCnC1mU3pUuynwCPOuVOB+4CfBDtQEREJnkBa/jOAYudciXOuFVgCzOtSZgrwcsfjV7s5LiIig0ggyX8ksLvTdmnHvs7WAp/peHwFkGZmWV1PZGa3mFmRmRVVVVX1Jt5B4WBzG+1LF4uIhKdAkr91s69r5vsucIGZrQYuAMoA7xFPcm6Rc67AOVeQk5Nz3MGGmnOOR97ZScGPXuLht3aGOhwRkV6LDaBMKZDXaXsUUN65gHOuHLgSwMxSgc8452qDFeRgUNvUxu1PruWlzXsBONDYGuKIRER6L5CWfyGQb2bjzCwemA8s7VzAzLLN7MNzfR94KLhhhlZxZR2fXvgWr22p5Aef6jrWLSISfnpM/s45L7AAWA5sBp50zm00s/vM7PKOYrOALWa2FRgG/Gc/xTvg3t5ezRUL36auuY3HvjyTm84dh3XXESYiEkYC6fbBObcMWNZl392dHj8FPBXc0IKn8mAzuUMSj/t5y9ZX8O0laxiTlcwfb5zBiIykfohORGTgRfwdvs9vqGDGj1+mpKr+uJ739zVlLHhsFaeMSucvXz1LiV9EIkpALf9w5Zxj4avbATjQ1Bbw8/65voLbnlzL9LGZPHzDdJLjI/plEpEoFNEt/xU7alhfdnwXHb1dXM03Hl/NaXkZPHS9Er+IRKaITv6/f6PkuMoXV9bz1UffY1x2Cg9dP52UBCV+EYlMEZv8iyvrefn9Sk7LywiofG1jGzf9sZA4TwwPXT+d9KS4fo5QRCR0Ijb5P726FE+Mce3MMT2Wdc5xx1/XUra/iUVfOoO8zOQBiFBEJHQiMvk753h2XQVnn5hFdmp8j+X/9O4ulm/cyx1zJ3HGmMwBiFBEJLQiMvmvL6tl175GLjt1RI9lt+2t40fPbWbWpBxuPnf8AEQnIhJ6EZn8n11XQZzHuGTq8GOW8/sd3//bepLjPfz0sx8jJka37opIdIi45O+c47l1FZyXn0N68rEHbZcU7qZo137uunQy2akJAxShiEjoRVzyX737AGUHmvjUqSccs1xVXQs/+edmzhqfxVVnaNVJEYkuEZf8/7W1GjO46KRhxyz361e20djq40dXnIxppjYRiTIRl/xX7tzH5OFDjtnls2tfA4+t+ID50/M4MSd1AKMTERkcIir5t3r9vLdrPzPGHftyzf99YStxnhi+dVH+AEUmIjK4RFTyX19WS3ObnzOPkfzf33OQpWvLufHcsb2a5vlD5bXNzP3FGzz1XmmvzyEiEioRNXnNyh01AEw/RvL/w792kBTn4cvn9e2a/g+T/ra9dX06j4hIKATU8jezuWa2xcyKzezObo6PNrNXzWy1ma0zs0uDH2rPVu7Yx4Tc1KNetll5sJm/rynjcwWjyEju+c7fY0mIjUG3BYhIuOox+ZuZB1gIfAKYAlxtZl0Xsv132pd3nEb7Gr+/DXagPfH5HUU7j93f/8g7u/D6HTecM65Pv2vBxyfw8PXTiY+NqF4zEYkigXT7zACKnXMlAGa2BJgHbOpUxgFDOh6nA+XBDDIQmysOUtfiPWp/f3Orj0dX7GL25GGMzU7p0++6fc6kPj1fRCTUAmm6jgR2d9ou7djX2b3AtWZWSvtav9/o7kRmdouZFZlZUVVVVS/CPbrVuw8AcProod0eX7ahggONbdx4bt9a/SIikSCQ5N9dz7brsn01sNg5Nwq4FPiTmR1xbufcIudcgXOuICcn5/ijPYbivXWkxHsYNbT7tXafXVfB6MzkY14JJCISLQJJ/qVAXqftURzZrXMT8CSAc+4dIBHIDkaAgSquqmdCbupR79Y90NjGFdNG6m5eERECS/6FQL6ZjTOzeNoHdJd2KfMBcBGAmU2mPfkHt1+nB9v21jMhN+2YZa6Y1rW3SkQkOvWY/J1zXmABsBzYTPtVPRvN7D4zu7yj2O3Al81sLfA4cL1zrmvXUL+pbWqjsq6F/GFHn6rh9NEZfR7oFRGJFAHd5OWcW0b7QG7nfXd3erwJOCe4oQWuuLIegAnHmKfnytM1c6eIyIci4kL17R3Jv7uW/xljhvL1WSeqy0dEpJOImN5hW2Ud8bExjBp65MLraYlx3DH3pBBEJSIyeEVEy7+4sp4Tc1LxaL4FEZGARETy31bZfpmniIgEJuyTf2Orl7IDTeQr+YuIBCzsk39JVQPOoZa/iMhxCPvkf+gyz0GS/Jtafdy0uJA/r9gV6lBERI4q7JN/2YEmAPK6udJnoPn8jm8uWc3L71eyateBUIcjInJUYZ/8q+paSEuIJSneE+pQ+OGzm3hx0140fZCIDHYRkfxzhnS/ctdAemzFByx+eyc3nTuOEendzywqIjJYhH3yr6xrJjcttMm/cGcN9yzdwAUTc/h/l04OaSwiIoGIgOTfQk5aYkh//9ceXcWoocn86upputFMRMJCWE/v4Jyj8mBLSFv+T68uIynOw2NfPpP0pLiQxSEicjzCuuVf3+Klqc0X8m6fH376ZCYOO/ZaAiIig0lYt/wr61oAyA3RgG9uWiLnTMjiqjM0XbSIhJfwTv4HO5J/iPr8X7ztfOI9Yf3Hk4hEqYAyl5nNNbMtZlZsZnd2c/znZram42ermQ3IHU5V9R8m/9C0/BNiPUddE9jvHD94ZgN/W1U6wFGJiPSsx5a/mXmAhcBs2hdzLzSzpR2rdwHgnPtOp/LfAKb1Q6xHqDzYDISu5X8sy9ZX0OL1c6CpTauIicigE0jLfwZQ7Jwrcc61AkuAeccofzXt6/j2u6q6FuJjYxiSNPh6r1q8/lCHICJyVIEk/5HA7k7bpR37jmBmY4BxwCtHOX6LmRWZWVFVVdXxxnqEyroWclITjtr1Eio5aQlcMDGH0Zmhn29IRKQ7gST/7jKrO0rZ+cBTzjlfdwedc4uccwXOuYKcnJxAYzyqyrrmkF3pcyxPfGUmD18/nVjd8CUig1Qgyb8UyOu0PQooP0rZ+QxQlw8Q8hu8jiYh1kOMEr+IDGKBJP9CIN/MxplZPO0JfmnXQmY2CRgKvBPcEI+usq5lUA72iogMdj0mf+ecF1gALAc2A0865zaa2X1mdnmnolcDS5xzR+sSCqpWr5/aprZB2fIXERnsArpMxjm3DFjWZd/dXbbvDV5YPasK8d29x+PNbdVkpsQzZcSQUIciIgKE8dw+h6Z2GOTdPutLD3Ddwyv59SvbQh2KiMghg+8C+QBV1rXf4JUzyLt9du5rBNqXeBQRGSzCNvkf6vYZxMnfE2MMTY4jVvP/iMggE7ZZqa7ZC8CQQTyH/o8+fTJPfOUsslLij+t5Pr+jqfWjWyUaWryU7m8MdngiEsXCtuVf3+LFE2MkxA7e768zx2f1WKbF6+PWP68mLTGWn3/+NA42t/GlB1diBk9//RzKDzTxxQdX0Orz8687LhyAqEUkGgzezNmDxhYfyfFHn1UzHLT5/Cx4bDUvbd7Ltso6Dja38cUHV7Jm9wFqGlrZUd3AZx94h+1VDTS2dHvTtIhIr4Rt8q9v9ZKaEF5/uLy+tYpVH+wH2pegvOOpdby4aS9pibE0tPj44oMr2VRey5isZPY3tPLZB96muc3HjLGZIY5cRCJN2Cb/xhYvyfGeUIcRsI3lB7lxcSG/eaUYgPuXb+Hp1WXcNnsiM8ZmsqO6gU3ltSy85nSm5WVwsNlLvCeGJ796FhOHp4Y4ehGJNGGb/BtafWHV8i870ITP7/A7x59X7OK3r23n6hl5fOPCCcR6jNgYY+E1pzNn6nDGZKUwcVgqf/na2ZyYo8QvIsEXPtmzi4YWL0MSB++VPp3FeWIYmhxHUpyHjeUHeWNrFR+flMMP552MmfG9S07ia7MmcFpeBgDfmT2Rb1+cH9bjGSIyuIVt8m9s9XFC+uC+u/dDP77iFJITPNz2xBrWltZyysh0fnPN6Yeu/5+Qe2TrXolfRPpT2Cb/+hYvKWHS7XPKqHQAUhJiGTU0iQevLwib2EUkMoVtBmof8A2v8H999TRiY2JITw6P7ioRiVxhO+Db2OYjNSF8rvYByEpN6NfEv7O6gScKP+i38wfC73cM0KzeItIHYZv8nSPsWv796Y2tVVz+mzf5t7+uZ3PFQR5f2T9fAvsbWvF3M0ldc5uPX7y0lSn3PM+jK0L7BSQiPQvr7BlOl3r2p8Vv7eC+ZzcR0zFIfNX/vU1Dq4/83FSKdu3nK+eP7/MAcm1jG//1/GYeX7mbX84/DTPjgvwchiTFsmz9Hn68bDNlB5oAKO/4V0QGr4Cyp5nNBX4JeIA/OOf+q5synwPupX1x97XOuWuCGGe3ksOs2yfYfH7Hfz63mYfe2sHsKcP42Kh0fvrCVlp9fgCu+cMKWr1+Rg1N4t2Sfdz9qanEd5oLqbq+hWfXlnP1maNJiP3otfT6/LxZXM1ZJ2YR74nhufUV3Lt0E9X17TOpfvcva2nzOa6dOZpte+tZsaOGk4an8fiXZ3LdQysH9kUQkV7pMfmbmQdYCMymfTH3QjNb6pzb1KlMPvB94Bzn3H4zy+2vgDuL5pZ/Y6uXby1Zw4ub9nLjOeO465OTKT/QhNfvSE2I5UfPbSYuxmgFFjy2GoDs1ATeKq7mD9dNZ+3uA9z25Fqq61s4ZVQ6Z4xpn0KiuLKe259svyT1vnlTeW1LFa+8X8kpI9NZeM00vvjQSnJSEyg70MSj737A0OQ4fvTpk5k/PU9TV4uEkUCy5wyg2DlXAmBmS4B5wKZOZb4MLHTO7QdwzlUGO9DuRGuff1VdCzf/sZB1ZbXcc9kUbjhnHAB5mcl8++KJVNe3kBjnIT42hjueWscJ6YlU1Dbzi5faVxO746m1LN/YPqcQgN+1D9Q+9NYO7l++hQ/Ha+/++0aS4z384FNTuO6sMcR6Ynj1u7PITI7n5kcKyc9N4zsXTzzmIPbG8lpGZiSRkXx801qLSP8KJHuOBHZ32i4FzuxSZiKAmb1Fe9fQvc6557ueyMxuAW4BGD16dG/iPUxKGM3tEyy7axr54oMr2HOwmd9dewZzpg4/okx2agLXzhxDc5uPURlJtPr83LC4kOljMlm5s4blG/fyxZljuGBiDjc/UsTumkbuX76FlTtquOikXL4zeyJX/PYtzsvP4b55Uxk1NPnQuUdmJAHw55tnHjPObXvr+PGyzby6pYqvnD+e7186ObgvhIj0SSDJv7uRwq6Xe8QC+cAsYBTwLzM72Tl34LAnObcIWARQUFDQ5+sBo+1GqW1767j2wRU0tfr4880zOWPM0GOWT4zzcPaEbADW/GAOe+ua+faSNXz74nzmTB3Om9uqAbj9L2tJjY/l/qtO5aozRmFmrL1nDklxvZsye+macha9UUJyvIc4j9HQ6j3+yopIvwoke5YCeZ22RwHl3ZR51znXBuwwsy20fxkUBiXKo0iJogHf+hYvn/vdO8R2zPR50vAhx/X89OQ40pPjWPat8w7tS4pv76M/a3wW93/2Y4da9dD7LrX42Bj2HGzm2jNH862LJzL7Z6/36jwi0r8C+R9eCOSb2TigDJgPdL2S5xngamCxmWXT3g1UEsxAuxNNLf8Wr5/cIQk8etOZjMlKCco5Tx89lH9+6zwmDUsjJiY4cwk9fMN0MlPiNRupyCDXY/Z0znnNbAGwnPb+/IeccxvN7D6gyDm3tOPYHDPbBPiA7znn9vVn4BA9A74nj0inYMxQFn7hdIYNCd5kdmbG5BOO7y+InkzXwjMiYSGg7OmcWwYs67Lv7k6PHXBbx8+AiZYB3/kzRjN/Rt8HyENlRUkNBT96kSumjSQlIZaZ47OYGcD6xiLSf8K26ZwQG6PrysOAmbGtsh6A3/9rBwDzTmtQ8hcJsbBN/tF8g1c4+cmVpxAfG8PSNeXUNbfx3q79oQ5JRAjj5B/tUzuEi9lThgFwwcQcAGbd/yrOwYqSfYzISCIvM/lYTxeRfhK2/SYpUTLYG4n+uaGCzy96l5++sCXUoYhErbDNoNF0mWckyU5NoL7FR4vXR6vXH+pwRKJW2GbQ5Ci50ifS/OmmM4mJgct+/SbOwcodNQwbkkBuWiJm7Xcli0j/C9vkrwHf8JTU6Uv75ff38vzGPUD7+zl7yjB+/vnTQhWaSFQJ2z7/aLnBK1LlpiWSnvTRTJ+tXj9VdS0hjEgkuoRtBg239XvlcA9eX4BhlO5vpNXn566nN4Q6JJGoErbJP1ndPmHtw5XDxmsOIJGQCNtun2iZ2kFEpD+Eb/JXy19EpNfCN/lrwFdEpNfCN/mr5S8i0mthm/w1t4+ISO+FbfLXTV4iIr0XUPI3s7lmtsXMis3szm6OX29mVWa2puPn5uCHejhN7xDZNpUfpKSqnpKqenbtawh1OCIRp8fms5l5gIXAbNoXai80s6XOuU1dij7hnFvQDzF2Sy3/yLSxvJafv7iVlzZXAmAG0/Iy+NvXzwGgqq4Fr99PQqyHVq+f4enBW9ZSJJoEkkFnAMXOuRIAM1sCzAO6Jv8BpekdIk/Rrho++as3GZL40XubnZpAY6uPsgNNPPDadv707i4AEuNiGJGRxCu3zwpRtCLhLZAMOhLY3Wm7FDizm3KfMbPzga3Ad5xzu7sWMLNbgFsARo/u3Zq0mSnxpCXGkpao5B9JMlPi8ZjxzQsncNN540mK8+B3jm8+vprXt1Yx6/5XDyufmhDHwSbvoe0P9jVysLmNk0emD3ToImEpkAxq3exzXbb/ATzunGsxs68CfwQuPOJJzi0CFgEUFBR0PUdArjx9FLOnDNPUvxHml/NPw++O7M7LSo3HOZg/fTRfnXUi2anxNLf6+e/l7/PCxr1sKKvlgde3s2x9BWmJcay9Z06IaiASXgJJ/qVAXqftUUB55wLOuX2dNn8P/HffQ+ueJ8bISI7vuaCElaN1491z2VTu/MRk0pPiDu37cF6g6voWPvXrN0lNiGVsdgql+5t4dl059c1e5s8YTXObj2dWl1FS3cDIjCR21zRy1ycnY9Zde0YkugSS/AuBfDMbB5QB84FrOhcwsxOccxUdm5cDm4MapUStxDhPt3/lTchJZUR6Il+YOYZrZ47ht68V87vXS1jw2GpiDCpqm3n03V3sa2g97Hkf1DTy4ua9zJ48jB3VDTx96zm6eECiUo+feuec18wWAMsBD/CQc26jmd0HFDnnlgLfNLPLAS9QA1zfjzGLcOO547jx3HGHts85MZvivfW0+R1vbK3ily9v46KTcrl4yjC27KnD53f86d1dvLBpL8Chf/fVtyj5S1Qy53rV9d5nBQUFrqioKCS/WyJXcWUdz6wu59PTRjIh96Ppog82t/Hq+5WcNT6L9WW1lNc284NnNvD692YxJislhBGLHB8ze885V9DX86jJIxFlQm4a371k0hH7hyTGMe+0kQBcNCSRv60qHejQRAaVsJ3eQUREek/JX0QkCin5i4hEISV/EZEopOQvUc/vD80VbyKhpOQvUe3LjxQx5Z7nqa5vCXUoIgNKyV+i0pDE9ukiyg8009zmp6bLncAikU7JX6LSx0/K5aXbLuAnV54S6lBEQkI3eUlU8sQYE3JT2bKnDoAfPruJ6vpWfnzFyWzbW8+QpFgKd+7nu3MmkaRV4yQCKflLVEuIbf/j91/bqgG44rdvH3b8osm5nH1i9oDHJdLflPwlqp0/MYc/fKmAUZlJ3Lt0I6flDaX8QBNjspL59SvFoQ5PpN8o+UtUi4+N4eIpwwBYcstZh/a/W7JPyV8imgZ8RUSikJK/iEgUUvIXEYlCASV/M5trZlvMrNjM7jxGuavMzJlZnxcaEBGR/tNj8jczD7AQ+AQwBbjazKZ0Uy4N+CawIthBiohIcAXS8p8BFDvnSpxzrcASYF435X4I/A/QHMT4RESkHwSS/EcCuzttl3bsO8TMpgF5zrlnj3UiM7vFzIrMrKiqquq4gxURkeAIJPlbN/sOzYFrZjHAz4HbezqRc26Rc67AOVeQk5MTeJQiIeLzO7ZX1eOcpn2WyBJI8i8F8jptjwLKO22nAScDr5nZTmAmsFSDvhIJbnnkPS7639dZvfsAzjkaW728s30fXp8/1KGJ9Ekgd/gWAvlmNg4oA+YD13x40DlXCxya/MTMXgO+65wrCm6oIgNnZEYSQ5PjGDU0mfVltXz90VXsOfjRcNaD1xVw0eRhIYxQpG96TP7OOa+ZLQCWAx7gIefcRjO7Dyhyzi3t7yBFBlpeZjKr757DjuoGPv7T12hs9QIwa1IOr22porHVh9/vKNxZwxOFu4mPjeH9PXX8+ycn0+Zz/GNdOa9vqeIHn5rC3JOH45yjdH8TuUMSaPM5Xnm/klc272XS8CH4/H7Oy8/hY3kZIa61RBMLVV9mQUGBKyrSHwcy+FXVtZCVEk9MjFFcWcfFP3uD8/KzKalqoOxA02FlY2MMr9+RGBdDc5ufzxWM4oT0JJ5dV872qgagfT6hVu/h3UZXnj6Sb1yYT1Zq/KGFZkS6Y2bvOef63K2uid1EepCTlnDocWJc+9z+b2/fx7kTsvneJZPIHZLA2KwUFjy2isyUBC4/bQQfn5TDKfe+wJNFpZjBmeMy2V7VQJzHuGbGaC495QSq6lqobWrjFy9tZemacv62qoyrZ+TxkytPBWB3TSNDkuJIT9KXgQSfWv4ix2nljhrGZacc9qXQnd+/UUJCXAxzTx5OblrioYXiY2IOv4Du7r9vYEd1A+tKa8nPTWXm+Cxe2LSHrXvrAbj0lOG8+n4V6UlxXDAxh3/7xEnEeYw0/YUQlYLV8lfyFxkk5vz8dbburccTY8wYm8k7JfsOO56WEEuz14fX7zj7xCz+fPPMEEUqoaRuH5EIc+9lU6mobebCk3IZmhLP7ppGqupb+NioDPzOseiNEl7YtJfquhb2N7SFOlwJc2r5i4SZm/9YxAc1Ddxz2VR27WukoraJvKHJfG56Xs9PlrCnlr9IFNu6t54v/OGjORRHZyr5y/FR8hcJM5+fnscJ6YmMzU4hOzWef6yt4M3iKmbd/ypjs1NYfMOMUIcoYUDJXyTMzJ4yjNlTPrq7eHtlPW8WV1Hb1MbmioMhjEzCiVbyEglzt82ZxMb/mMslU4dT1+zlpsWFfP9v60MdlgxyavmLRABPjJGeHEdjq483tlUR54khMyWOtMQ4vnrBiUeU9/sdW/bWUdfsZca4zBBELKGmq31EIkRzm4+ahlYWv72TRW+UAO3TTVw0OZfk+FhunzORt4qreat4H29vr6a6vpUYg3X3XkJqgtqB4UJX+4jIYRLjPIzISOIr54/n7BOzWLGjhv97bTvLN+4F4OnVZUD7dBXn5efQ1Orj+Y17ND11lFLyF4kwWakJzJqUy9knZnPtzDHsqW3i4bd2csaYoZwzIZv83FTMjIff2sHzG/eEOlwJESV/kQgVHxvDyIwkRmYkccYY9evL4XS1j4hIFFLyFxGJQgElfzOba2ZbzKzYzO7s5vhXzWy9ma0xszfNbErwQxURkWDpsc/fzDzAQmA27Yu5F5rZUufcpk7FHnPOPdBR/nLgZ8DcfohXRILsicLdvLR5L+lJ8ZTub+QbF+ZT39LG5wryMLOeTyBhKZAB3xlAsXOuBMDMlgDzgEPJ3znX+Z7yFCA0Nw+ISMDiY9v/8P/JP98/bP+tj60C4MxxWYzNThnwuGRgBJL8RwK7O22XAmd2LWRmtwK3AfHAhUGJTkT6zeUfG0FGUjxTRwwhOy0Bv3M8vaqM8tomfvd6CV6/2nCRLJA+/+7+7jviU+GcW+icOxH4N+Dfuz2R2S1mVmRmRVVVVccXqYgEVVpiHJ889QTGZqeQmhDLkMQ4rjt7LFNHpIc6NBkAgST/UqDzROGjgPJjlF8CfLq7A865Rc65AudcQU5OTuBRikjIOedobvOFOgwJkkC6fQqBfDMbB5QB84FrOhcws3zn3LaOzU8C2xCRsLZ84x5+93oD+cNSWf3BAYp27ae6voWXb7uA8TmpoQ5P+qjH5O+c85rZAmA54AEecs5tNLP7gCLn3FJggZldDLQB+4Hr+jNoEek/8Z72nt77l285tC8vM4lxWSlU1bVQur8JT4wxOjNZVwOFMc3qKSKHaW7z8cKmvYzPTuFgcxsn5qQybEgibxdXc02npSP/eOMM/H7H6g/2s2NfI3ddOpnh6Yk0tMnWe2IAAAizSURBVHjZua+BScPSiPXoPtJgC9asnkr+IhKQA42t3PXMBgCeW1fRY/nffuF05kwZpi+AINOUziIyoDKS41l4zek0tfrISonnhPQkpo3OYExWMl/4/QqSEzzUN3uZNSmXxW/v5PYn19LU5uPKaSNJTvCQHB9LXbOXG88ZS/6wtFBXJ+qp5S8iQdXi9XHT4iK8fj/vltQccXzG2ExyhyRw83njOS0vIwQRhje1/EVkUEqI9fDoze33ga7cUUNiXAzJ8bGkJHiY8/M3KNxVg3OQEh9L2f4mRmQksnNfAxW1zVTVtTDvtJFHfCk45zS4HGRq+YvIgKlpaCU+NoaP/ccL+I5xB3F2agLV9S2MzEii7EAT0L4k5cWTh1FxsJnRmcm8sbWK1IRY5kwdxj2XTR2oKoScBnxFJGw9t66C5jYfu/c3MmxIIlkp8UwclsYPn93E5oqDlNc2k50aT3V9K6ePzmDVBweOOMe47BT2N7bi8zty0xI4f2JOVHwJKPmLSNRo8fpo9fqJj42hqdVHRnI8AD9dvoV/rCuntqmNNq+fjOR4MlPiue7ssYzOTGbGuMhbwUzJX0Skw8JXi/nre6WUVDcctj81IRav389tsycyMiOZiybnYtY+LhGulPxFRLoo3d/IhrJa1pbW8ua2ataX1XZb7rtzJlK4cz8jMpJIivNw1Rmj8MQYk4YP/ktQlfxFRHpQ29RGcWUde2pbWLah4pg3p8XGGM/ceg6Vdc04B9ur6imurMfnh//+zCmD5mY1JX8RkePU3OajuLKesdkp+HyOupY2/r6mnH9uqGBD2cGjPu+tOy9kZEbSAEZ6dLrOX0TkOCXGeTh55EfrFaQnx3Hrxydw5ekj+duqMtKT4vD5HSePHMKEnDSWb9zDHX9dx1NFpVTVN1MwJpOmNh/zp+fh9TviBslfA72hlr+IyFE8t67i0LKWXcXHxvD692ZxQvrA/kWgbh8RkX7m9fnZWH6QzJR4PqhpxOd3LH57J5srDlJR28zkE4YQG2M88MUziPfEkJOWgN/vMIMWr5/EOA8+v8MTE7y7k5X8RURCpKSqnhsWF7JrX2NA5b9y/njGZKVw8ZRcmlp95A1NJqaXXwhK/iIiIVbX3Mb/vrCVGDNe3VLJ1BFD2LKnjmmjM3inZB9jMlN4s7j6iOf95pppfOrUEb36nQM64Gtmc4Ff0r6S1x+cc//V5fhtwM2AF6gCbnTO7eprcCIig1laYhz3Xt4+pcTdl03ptkzhzhriPDE8t66cNl97t9GBxraBDLNbPSZ/M/MAC4HZtC/mXmhmS51zmzoVWw0UOOcazexrwP8An++PgEVEwsn0se1TTJyWl0FtYxuVde0T04VaIC3/GUCxc64EwMyWAPOAQ8nfOfdqp/LvAtcGM0gRkUiQnhzHb79wRqjDACCQi1RHArs7bZd27Duam4B/9iUoERHpX4G0/Lsbku52lNjMrgUKgAuOcvwW4BaA0aNHBxiiiIgEWyAt/1Igr9P2KKC8ayEzuxi4C7jcOdfS3Ymcc4uccwXOuYKcnJzexCsiIkEQSPIvBPLNbJyZxQPzgaWdC5jZNOB3tCf+yuCHKSIiwdRj8nfOeYEFwHJgM/Ckc26jmd1nZpd3FLsfSAX+YmZrzGzpUU4nIiKDQEDX+TvnlgHLuuy7u9Pji4Mcl4iI9KPwnZJORER6TclfRCQKhWxuHzOrAo53Cohs4MiJMqJLtL8Gqn901x/0GkxyzvV5vcmQLebinDvuaz3NrCgYExqFs2h/DVT/6K4/6DUws6DMiKluHxGRKKTkLyIShcIt+S8KdQCDQLS/Bqq/RPtrEJT6h2zAV0REQifcWv4iIhIESv4iIlFo0CR/M5trZlvMrNjM7uzmeIKZPdFxfIWZje107Psd+7eY2SUDGXew9Lb+ZjbWzJo65lRaY2YPDHTswRBA/c83s1Vm5jWzq7ocu87MtnX8XDdwUQdXH18DX6fPQFjOrRVA/W8zs01mts7MXjazMZ2Ohf1noI/1P/733zkX8h/a1wbeDowH4oG1wJQuZb4OPNDxeD7wRMfjKR3lE4BxHefxhLpOA1j/scCGUNdhAOo/FjgVeAS4qtP+TKCk49+hHY+HhrpOA/kadByrD3UdBqD+HweSOx5/rdP/gbD/DPSl/r19/wdLy//QUpHOuVbgw6UiO5sH/LHj8VPARWZmHfuXOOdanHM7gOKO84WTvtQ/EvRYf+fcTufcOsDf5bmXAC8652qcc/uBF4G5AxF0kPXlNYgEgdT/VedcY8fmu7SvLQKR8RnoS/17ZbAk/0CWijxUxrVPM10LZAX43MGuL/UHGGdmq83sdTM7r7+D7Qd9eQ8j4f2Hvtcj0cyKzOxdM/t0cEMbEH1ZLjYSPgN9XS73uN//kE3v0EUgS0UerUzAy0wOYn2pfwUw2jm3z8zOAJ4xs6nOuYPBDrIf9eU9jIT3H/pej9HOuXIzGw+8YmbrnXPbgxTbQOjLcrGR8Bno63K5x/3+D5aWfyBLRR4qY2axQDpQE+BzB7te17+ju2sfgHPuPdr7DSf2e8TB1Zf3MBLef+hjPZxz5R3/lgCvAdOCGdwA6MtysZHwGejTcrm9ev9DPdDRMVgRS/sgzTg+GuyY2qXMrRw+4Plkx+OpHD7gW0L4Dfj2pf45H9aX9sGiMiAz1HUKdv07lV3MkQO+O2gf6Bva8Tis6h+E12AokNDxOBvYRpfBwsH+E+D/gWm0N27yu+wP+89AH+vfq/c/5JXuVIFLga0dlburY999tH/DASQCf6F9QHclML7Tc+/qeN4W4BOhrstA1h/4DLCx48OyCrgs1HXpp/pPp7111ADsAzZ2eu6NHa9LMXBDqOsy0K8BcDawvuMzsB64KdR16af6vwTsBdZ0/CyNpM9Ab+vf2/df0zuIiEShwdLnLyIiA0jJX0QkCin5i4hEISV/EZEopOQvIhKFlPxFRKKQkr+ISBT6/62TgCXxP/u1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluator import *\n",
    "evaluator = Evaluator()\n",
    "metricsPerClass = evaluator.GetPascalVOCMetrics(boundingboxes, IOUThreshold=0.5)\n",
    "print(\"Average precision values per class:\\n\")\n",
    "# Loop through classes to obtain their metrics\n",
    "mAP=0\n",
    "counter=0\n",
    "for mc in metricsPerClass:\n",
    "    # Get metric values per each class\n",
    "    c = mc['class']\n",
    "    precision = mc['precision']\n",
    "    recall = mc['recall']\n",
    "    average_precision = mc['AP']\n",
    "    ipre = mc['interpolated precision']\n",
    "    irec = mc['interpolated recall']\n",
    "    # Print AP per class\n",
    "    mAP=average_precision+mAP\n",
    "    print('%s: %f' % (c, average_precision))\n",
    "\n",
    "print('map is:',mAP/80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.07290217209136615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "coord=pred_final[:,:4].cpu().detach().numpy()\n",
    "conf=pred_final[:,4:5].cpu().detach().numpy()\n",
    "mat=np.hstack((conf,coord))\n",
    "\n",
    "classes=pred_final[:,5:].max(1)[1].cpu().detach().numpy()\n",
    "classes=np.array([classes]).T\n",
    "\n",
    "mat=np.hstack((classes,mat))\n",
    "mat=np.array(mat)\n",
    "\n",
    "df=pd.DataFrame(mat,index=None,columns=None)\n",
    "df[0]=df[0].apply(lambda x: int(x))\n",
    "\n",
    "df.to_csv('test.txt',sep=' ',header=False,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('test.txt',mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([1,2,2,3,4,2,3,1,4])\n",
    "print(a.max(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=(inp).squeeze(0)\n",
    "image=np.array(image.cpu())\n",
    "print(image.shape)\n",
    "image =  image[:,:,::-1].transpose((1,2,0))\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "all_files = glob.glob('plots/' + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in sorted(all_files):\n",
    "    print(filename)\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=1, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# gca stands for 'get current axis'\n",
    "\n",
    "title_list=['AIoU_train','Loss_train','NClass_train','NConf_train','PClass','PConf']\n",
    "\n",
    "fig = plt.figure(figsize=(30, 10))\n",
    "fig.suptitle('KL for xy loss')\n",
    "fig.subplots_adjust(hspace=0.3, wspace=-.6)\n",
    "colors = ['#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c']\n",
    "i=2\n",
    "k=0\n",
    "while i <18:\n",
    "    ax = fig.add_subplot(2, 9, i)\n",
    "    frame.plot(x =1 , y = i,ax=ax,legend=False)\n",
    "    ax.set_title(title_list[k])\n",
    "    i=i+3\n",
    "    k=k+1\n",
    "plt.savefig('original.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
