{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import torch\n",
    "import helper as helper\n",
    "from dataset import *\n",
    "import imageio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  custom_loss import SinkhornDistance\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "n_points = 5\n",
    "a = np.array([[i, 0] for i in range(n_points)])\n",
    "b = np.array([[i, 1] for i in range(n_points)])\n",
    "\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.scatter(a[:, 0], a[:, 1], label='supp($p(x)$)')\n",
    "plt.scatter(b[:, 0], b[:, 1], label='supp($q(x)$)')\n",
    "plt.legend();\n",
    "\n",
    "\n",
    "x = torch.tensor(a, dtype=torch.float)\n",
    "y = torch.tensor(b, dtype=torch.float)\n",
    "print(y.shape)\n",
    "\n",
    "sinkhorn = SinkhornDistance(eps=0.1, max_iter=100)\n",
    "dist, P, C = sinkhorn(x, y)\n",
    "print(\"Sinkhorn distance: {:.3f}\".format(dist.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path='../labels/coco/labels/val2017/000000007108.txt'\n",
    "with open(label_path) as box:\n",
    "    box=box.read()\n",
    "    box=pd.DataFrame([x.split() for x in box.rstrip('\\n').split('\\n')],columns=['class','xc','yc','w','h'])\n",
    "\n",
    "b= box.values.astype(np.float32)\n",
    "bboxes=b\n",
    "b=torch.tensor(b)\n",
    "labels = b.T[0].reshape(b.shape[0], 1)\n",
    "one_hot_target = (labels == torch.arange(80).reshape(1, 80)).float()\n",
    "conf=torch.ones([b.shape[0],1])\n",
    "boxes=torch.cat((b.T[1:],conf.T,one_hot_target.T)).T\n",
    "\n",
    "img_path='../images/val2017/000000007108.jpg'\n",
    "img=cv2.imread(img_path)[:,:,::-1] \n",
    "\n",
    "sample={'images': img,\n",
    "        'boxes': boxes}\n",
    "\n",
    "(h,w,c)=img.shape\n",
    "\n",
    "bboxes[:,1]=bboxes[:,1]*w\n",
    "bboxes[:,2]=bboxes[:,2]*h\n",
    "bboxes[:,3]=bboxes[:,3]*w\n",
    "bboxes[:,4]=bboxes[:,4]*h\n",
    "bboxes[:,1]=bboxes[:,1]-bboxes[:,3]/2\n",
    "bboxes[:,2]=bboxes[:,2]-bboxes[:,4]/2\n",
    "bboxes[:,3]=bboxes[:,1]+bboxes[:,3]\n",
    "bboxes[:,4]=bboxes[:,2]+bboxes[:,4]\n",
    "print(bboxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import parameters as iap\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "\n",
    "\n",
    "image = sample['images']\n",
    "\n",
    "bbs = BoundingBoxesOnImage([\n",
    "    BoundingBox(x1=b[1], y1=b[2], x2=b[3], y2=b[4], label=b[0]) for b in bboxes], shape=image.shape)\n",
    "\n",
    "seq = iaa.OneOf([\n",
    "            iaa.Sequential([\n",
    "                iaa.LinearContrast(alpha=(0.1, 1.9)),\n",
    "                iaa.Fliplr(0.5)\n",
    "            ]),\n",
    "            iaa.Sequential([\n",
    "                iaa.Grayscale(alpha=(0.1, 0.9)),\n",
    "                iaa.Affine(\n",
    "                translate_px={\"y\": (-150, 150)}\n",
    "            )\n",
    "            ]),\n",
    "            iaa.Sequential([\n",
    "                iaa.Solarize(0.5, threshold=(0, 256)),\n",
    "                iaa.ShearX((-10, 10))\n",
    "            ]),\n",
    "            iaa.Sequential([\n",
    "                iaa.GaussianBlur(sigma=(0, 0.5)),\n",
    "                iaa.ShearY((-10, 10))\n",
    "            ]),\n",
    "            iaa.Sequential([\n",
    "                iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "                iaa.Affine(\n",
    "                rotate=(-30, 30)\n",
    "            )\n",
    "            ]),\n",
    "            iaa.Sequential([\n",
    "                iaa.HistogramEqualization(),\n",
    "                iaa.Affine(\n",
    "                translate_px={\"x\": (-150, 150)}\n",
    "            )\n",
    "            ]),\n",
    "            iaa.Sequential([\n",
    "                iaa.GaussianBlur(sigma=(0, 0.5)),\n",
    "                iaa.Affine(\n",
    "                scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}\n",
    "            )\n",
    "            ])\n",
    "        ])\n",
    "\n",
    "# Augment BBs and images.\n",
    "image_aug, bbs_aug = seq(image=image, bounding_boxes=bbs)\n",
    "\n",
    "# print coordinates before/after augmentation (see below)\n",
    "# use .x1_int, .y_int, ... to get integer coordinates\n",
    "for i in range(len(bbs.bounding_boxes)):\n",
    "    before = bbs.bounding_boxes[i]\n",
    "    after = bbs_aug.bounding_boxes[i]\n",
    "    print(\"BB %d: (%.4f, %.4f, %.4f, %.4f) -> (%.4f, %.4f, %.4f, %.4f)\" % (\n",
    "        i,\n",
    "        before.x1, before.y1, before.x2, before.y2,\n",
    "        after.x1, after.y1, after.x2, after.y2)\n",
    "    )\n",
    "\n",
    "# image with BBs before/after augmentation (shown below)\n",
    "# image_before = bbs.draw_on_image(image, size=2)\n",
    "# image_after = bbs_aug.draw_on_image(image_aug, size=2, color=[0, 0, 255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bboxes=bbs_aug.to_xyxy_array()\n",
    "bbs_aug=bbs_aug.remove_out_of_image().clip_out_of_image()\n",
    "\n",
    "ia.imshow(bbs_aug.draw_on_image(image_aug, size=2))\n",
    "\n",
    "labels=np.array([[box.label for box in bbs_aug.bounding_boxes]]).T\n",
    "new_bboxes=bbs_aug.to_xyxy_array()\n",
    "np.hstack((labels,new_bboxes))\n",
    "\n",
    "bboxes_final=helper.convert2_rel(np.hstack((labels,new_bboxes)),image_aug.shape)\n",
    "print(bboxes_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(bbs.draw_on_image(image, size=2))\n",
    "imageio.imwrite(\"elephants.jpg\", bbs.draw_on_image(image, size=2))\n",
    "bbs_aug.draw_on_image(image_aug, size=2)\n",
    "imageio.imwrite(\"elephants_aug.jpg\", bbs_aug.draw_on_image(image_aug, size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box=open(\"../detections/000000007108.txt\")\n",
    "box=box.read()\n",
    "box=pd.DataFrame([x.split() for x in box.rstrip('\\n').split('\\n')],columns=['class','conf','xc','yc','w','h'])\n",
    "b= box.values.astype(np.float32)\n",
    "b=torch.tensor(b)\n",
    "labels = b.T[0].reshape(b.shape[0], 1)\n",
    "objectness = b.T[1].reshape(b.shape[0], 1)\n",
    "one_hot_target = (labels == torch.arange(80).reshape(1, 80)).float()\n",
    "# conf=torch.ones([b.shape[0],1])\n",
    "\n",
    "boxes=torch.cat((b.T[2:],objectness.T,one_hot_target.T)).T\n",
    "print(boxes.shape)\n",
    "# plt.imshow(draw_rect(sample['images'], boxes))\n",
    "# plt.savefig('elephants.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import pickle as pkl\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_rect(im, cords, color = None):\n",
    "    \"\"\"Draw the rectangle on the image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    im : numpy.ndarray\n",
    "        numpy image \n",
    "    \n",
    "    cords: numpy.ndarray\n",
    "        Numpy array containing bounding boxes of shape `N X 4` where N is the \n",
    "        number of bounding boxes and the bounding boxes are represented in the\n",
    "        format `x1 y1 x2 y2`\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    numpy.ndarray\n",
    "        numpy image with bounding boxes drawn on it\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    im = im.copy()\n",
    "    h=im.shape[0]\n",
    "    w=im.shape[1]\n",
    "    cords[:,0]=cords[:,0]*w\n",
    "    cords[:,1]=cords[:,1]*h\n",
    "    cords[:,2]=cords[:,2]*w\n",
    "    cords[:,3]=cords[:,3]*h\n",
    "    if not color:\n",
    "        color = [255,255,255]\n",
    "    for cord in cords:\n",
    "        pt1, pt2 = (cord[0]-cord[2]/2, cord[1]-cord[3]/2) , (cord[0]+cord[2]/2, cord[1]+cord[3]/2)\n",
    "        \n",
    "#         pt1, pt2 = (cord[0], cord[1]) , (cord[2], cord[3])\n",
    "        \n",
    "        pt1 = int(pt1[0]), int(pt1[1])\n",
    "        pt2 = int(pt2[0]), int(pt2[1])\n",
    "    \n",
    "        im = cv2.rectangle(im.copy(), pt1, pt2, color, int(max(im.shape[:2])/200))\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> New yolo version</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO version2\n",
      "{'lr': 0.001, 'epochs': 90, 'resume_from': 15, 'coco_version': '2017', 'batch_size': 8, 'weight_decay': 0.0005, 'momentum': 0.9, 'optimizer': 'sgd', 'alpha': 0.5, 'gamma': 0, 'lcoord': 1, 'lno_obj': 0.5, 'iou_type': (0, 0, 1), 'iou_ignore_thresh': 0.5, 'tfidf': False, 'idf_weights': True, 'tfidf_col_names': ['img_freq', 'none', 'none', 'none', 'no_softmax'], 'augment': 0, 'workers': 0, 'path': 'test_iou', 'reduction': 'sum'}\n",
      "path already exist\n",
      "cuda:0\n",
      "Length of dataset is 117266\n",
      "\n",
      "Pgr:5.171149352753568% L:0.6401216983795166 IoU:0.7320887446403503 pob:0.48008647561073303 nob:0.0068601686507463455 PCls:0.9185643792152405 ncls:0.0010308304335922003123"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b759412a88d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp_raw_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresp_pw_ph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresp_cx_cy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresp_stride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minp_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_progress_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miou_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/faster_rcnn/lib/python3.8/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                     \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmomentum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0mparam_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dataset import *\n",
    "import timeit \n",
    "import cv2\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import timeit\n",
    "import torch.autograd\n",
    "import helper as helper\n",
    "import pandas as pd\n",
    "from torch import autograd\n",
    "\n",
    "\n",
    "\n",
    "net = Darknet(\"../cfg/yolov3.cfg\")\n",
    "inp_dim=net.inp_dim\n",
    "pw_ph=net.pw_ph.to(device='cuda')\n",
    "cx_cy=net.cx_cy.to(device='cuda')\n",
    "stride=net.stride.to(device='cuda')\n",
    "print('YOLO version2')\n",
    "\n",
    "hyperparameters={'lr': 0.001, \n",
    "                 'epochs': 90,\n",
    "                 'resume_from':15,\n",
    "                 'coco_version': '2017', #can be either '2014' or '2017'\n",
    "                 'batch_size': 8,\n",
    "                 'weight_decay': 0.0005,\n",
    "                 'momentum': 0.9, \n",
    "                 'optimizer': 'sgd', \n",
    "                 'alpha': 0.5, \n",
    "                 'gamma': 0, \n",
    "                 'lcoord': 1,\n",
    "                 'lno_obj': 0.5,\n",
    "                 'iou_type': (0, 0, 1),\n",
    "                 'iou_ignore_thresh': 0.5, \n",
    "                 'tfidf': False, \n",
    "                 'idf_weights': True, \n",
    "                 'tfidf_col_names': ['img_freq', 'none', 'none', 'none', 'no_softmax'],\n",
    "                 'augment': 0, \n",
    "                 'workers': 0, \n",
    "                 'path': 'test_iou', \n",
    "                 'reduction': 'sum'}\n",
    "\n",
    "print(hyperparameters)\n",
    "coco_version=hyperparameters['coco_version']\n",
    "if (hyperparameters['idf_weights']==True):\n",
    "    hyperparameters['idf_weights']=pd.read_csv('../idf.csv')\n",
    "else:\n",
    "    hyperparameters['idf_weights']=False\n",
    "        \n",
    "'''\n",
    "when loading weights from dataparallel model then, you first need to instatiate the dataparallel model \n",
    "if you start fresh then first model.load_weights and then make it parallel\n",
    "'''\n",
    "try:\n",
    "    PATH = '../pth/'+hyperparameters['path']+'/'\n",
    "    weights = torch.load(PATH+hyperparameters['path']+'_best.pth')\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we https://pytorch.org/docs/stable/data.html#torch.utils.data.Datasetare on a CUDA machine, this should print a CUDA device:\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "\n",
    "    if (torch.cuda.device_count() > 2):\n",
    "        print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(net)\n",
    "        model.to(device)\n",
    "        model.load_state_dict(weights)\n",
    "    else:\n",
    "        model=net\n",
    "        model.to(device)\n",
    "        model.load_state_dict(weights)\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    try:\n",
    "        os.mkdir(PATH)\n",
    "    except FileExistsError:\n",
    "        print('path already exist')\n",
    "    net.load_weights(\"../yolov3.weights\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "    if (torch.cuda.device_count() > 2):\n",
    "        print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(net)\n",
    "        model.to(device)\n",
    "    else:\n",
    "        model=net\n",
    "        \n",
    "if hyperparameters['augment']>0:\n",
    "    transformed_dataset=Coco(partition='train',coco_version=coco_version,transform=transforms.Compose([Augment(hyperparameters['augment']),ResizeToTensor(inp_dim)]))\n",
    "else:\n",
    "    transformed_dataset=Coco(partition='train',coco_version=coco_version,transform=ResizeToTensor(inp_dim))\n",
    "    \n",
    "\n",
    "\n",
    "dataset_len=(len(transformed_dataset))\n",
    "print('Length of dataset is '+ str(dataset_len)+'\\n')\n",
    "batch_size=hyperparameters['batch_size']\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=batch_size,\n",
    "                        shuffle=True,collate_fn=helper.collate_fn, num_workers=hyperparameters['workers'])\n",
    "\n",
    "\n",
    "if hyperparameters['optimizer']=='sgd':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=hyperparameters['lr'], weight_decay=hyperparameters['weight_decay'], momentum=hyperparameters['momentum'])\n",
    "elif hyperparameters['otimizer']=='adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hyperparameters['lr'], weight_decay=hyperparameters['weight_decay'])\n",
    "\n",
    "scheduler=optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max',patience=3)\n",
    "mAP_max=0\n",
    "epochs=hyperparameters['epochs']\n",
    "resume_from=hyperparameters['resume_from']\n",
    "break_flag=0\n",
    "prg_counter=0\n",
    "train_counter=0\n",
    "avg_no_conf=0\n",
    "avg_conf=0\n",
    "avg_pos=0\n",
    "avg_neg=0\n",
    "total_loss=0\n",
    "avg_iou=0\n",
    "for images,targets in dataloader:\n",
    "    train_counter=train_counter+1\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    images=images.cuda()\n",
    "    out=model(images,'cuda')\n",
    "    \n",
    "    true_pred=util.transform(out.clone().detach(),pw_ph,cx_cy,stride)\n",
    "    iou_list=util.get_iou_list(true_pred, targets,hyperparameters,inp_dim)\n",
    "    resp_raw_pred,resp_cx_cy,resp_pw_ph,resp_stride,no_obj,w_d=util.build_tensors(out,iou_list,pw_ph,cx_cy,stride,hyperparameters)\n",
    "    \n",
    "    \n",
    "    \n",
    "    loss=util.yolo_loss(resp_raw_pred,targets,no_obj,w_d,resp_pw_ph,resp_cx_cy,resp_stride,inp_dim,hyperparameters)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    stats=helper.get_progress_stats(true_pred,no_obj,iou_list,targets)\n",
    "    avg_conf=avg_conf+stats['pos_conf']\n",
    "    avg_no_conf=avg_no_conf+stats['neg_conf']\n",
    "    avg_pos=avg_pos+stats['pos_class']\n",
    "    avg_neg=avg_neg+stats['neg_class']\n",
    "    total_loss=total_loss+loss.item()\n",
    "    avg_iou=avg_iou+stats['iou']\n",
    "    prg_counter=prg_counter+1\n",
    "    \n",
    "    sys.stdout.write('\\rPgr:'+str(prg_counter/dataset_len*100*batch_size)+'%' ' L:'+ str(loss.item()))\n",
    "    sys.stdout.write(' IoU:' +str(stats['iou'])+' pob:'+str(stats['pos_conf'])+ ' nob:'+str(stats['neg_conf']))\n",
    "    sys.stdout.write(' PCls:' +str(stats['pos_class'])+' ncls:'+str(stats['neg_class']))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Accumulating evaluation results...\n",
      "DONE (t=11.78s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.210\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.509\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.119\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.131\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.218\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.295\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.205\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.383\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.242\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.390\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.459\n"
     ]
    }
   ],
   "source": [
    "import test\n",
    "mAP=test.evaluate(model, device,coco_version,confidence=0.01,iou_threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Wasserstein</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dim=inp_dim//32\n",
    "tt=[]\n",
    "dd=[]\n",
    "for j in range(len(iou_list)):\n",
    "    distribution=(iou_list[j].max(axis=0))[0]\n",
    "    for i in range(3):\n",
    "        slce=min_dim*(2**i)\n",
    "\n",
    "        ind=slce*slce*3\n",
    "        prev=0\n",
    "\n",
    "\n",
    "        tt.append(true_pred[0,prev:prev+ind,4].reshape(3,slce,slce).cpu())\n",
    "        dd.append(distribution[prev:prev+ind].reshape(3,slce,slce).cpu())\n",
    "        prev=ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(tt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected device cpu but got device cuda:0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-674f3742635d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtotal_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msinkhorn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtotal_dist\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/faster_rcnn/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data1/users/konsa15/workspace/notebooks/coco/yolo/custom_loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mu1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m  \u001b[0;31m# useful to check the update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mu1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data1/users/konsa15/workspace/notebooks/coco/yolo/custom_loss.py\u001b[0m in \u001b[0;36mM\u001b[0;34m(self, C, u, v)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"Modified cost for logarithmic updates\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;34m\"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected device cpu but got device cuda:0"
     ]
    }
   ],
   "source": [
    "from  custom_loss import SinkhornDistance\n",
    "\n",
    "\n",
    "\n",
    "sinkhorn = SinkhornDistance(eps=0.1, max_iter=100,reduction='sum')\n",
    "total_dist=0\n",
    "for i in range(len(tt)):\n",
    "    dist, P, C = sinkhorn(dd[i], tt[i])\n",
    "    total_dist+=dist\n",
    "    \n",
    "print(total_dist/8)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import timeit\n",
    "from dataset import *\n",
    "import torchvision.ops.boxes as nms_box\n",
    "import helper as helper\n",
    "from utils import *\n",
    "from BoundingBox import BoundingBox\n",
    "from BoundingBoxes import BoundingBoxes\n",
    "import json\n",
    "\n",
    "net = Darknet(\"../cfg/yolov3.cfg\")\n",
    "inp_dim=net.inp_dim\n",
    "pw_ph=net.pw_ph.cuda()\n",
    "cx_cy=net.cx_cy.cuda()\n",
    "stride=net.stride.cuda()\n",
    "\n",
    "start_time = time.time()\n",
    "'''\n",
    "when loading weights from dataparallel model then, you first need to instatiate the dataparallel model \n",
    "if you start fresh then first model.load_weights and then make it parallel\n",
    "'''\n",
    "try:\n",
    "    PATH = '../pth/pretrained32_precomp_obj_soft.pth'\n",
    "    weights = torch.load(PATH)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(net)\n",
    "    else:\n",
    "        model=net\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(weights)\n",
    "    model.eval()\n",
    "except FileNotFoundError: \n",
    "    net.load_weights(\"../yolov3.weights\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "    model=net\n",
    "    if torch.cuda.device_count() > 3:\n",
    "      print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "      model = nn.DataParallel(net)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('testing with '+ PATH +'\\n')\n",
    "transformed_dataset=Coco(partition='val',coco_version='2014',subset=0.1,\n",
    "                                           transform=transforms.Compose([\n",
    "                                            ResizeToTensor(inp_dim)\n",
    "                                           ]))\n",
    "\n",
    "\n",
    "\n",
    "dataset_len=(len(transformed_dataset))\n",
    "print('Length of dataset is '+ str(dataset_len)+'\\n')\n",
    "batch_size=2\n",
    "\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=batch_size,\n",
    "                        shuffle=True,collate_fn=helper.my_collate, num_workers=4)\n",
    "\n",
    "true_pos=0\n",
    "false_pos=0\n",
    "counter=0\n",
    "iou_threshold=0.5\n",
    "confidence=0.01\n",
    "recall_counter=0\n",
    "max_detections=None\n",
    "prg_counter=0\n",
    "annotations=[]\n",
    "for images,targets,img_meta in dataloader:\n",
    "#     print(images)\n",
    "    inp=images.cuda()\n",
    "    raw_pred = model(inp, torch.cuda.is_available())\n",
    "    targets,anchors,offset,strd,mask=helper.collapse_boxes(targets,pw_ph,cx_cy,stride)\n",
    "\n",
    "    raw_pred=raw_pred.to(device='cuda')\n",
    "    true_pred=util.transform(raw_pred.clone(),pw_ph,cx_cy,stride)\n",
    "\n",
    "    sorted_pred=torch.sort(true_pred[:,:,4],descending=True)\n",
    "    pred_mask=sorted_pred[0]>confidence\n",
    "    indices=[(sorted_pred[1][e,:][pred_mask[e,:]]) for e in range(pred_mask.shape[0])]\n",
    "    pred_final=[true_pred[i,indices[i],:] for i in range(len(indices))]\n",
    "\n",
    "    pred_final_coord=[util.get_abs_coord(pred_final[i].unsqueeze(-2)) for i in range(len(pred_final))]\n",
    "\n",
    "    indices=[nms_box.nms(pred_final_coord[i][0],pred_final[i][:,4],iou_threshold) for i in range(len(pred_final))]\n",
    "\n",
    "    pred_final=[pred_final[i][indices[i],:] for i in range(len(pred_final))]\n",
    "\n",
    "\n",
    "    abs_pred_final=[helper.convert2_abs_xywh(pred_final[i],img_meta[i]['img_size'],inp_dim) for i in range(len(pred_final))]\n",
    "    \n",
    "    annotations=[*annotations,*helper.transform_to_COCO(img_meta,abs_pred_final)]\n",
    "    sys.stdout.write('\\rPgr:'+str(prg_counter/dataset_len*100*batch_size)+'%')\n",
    "    prg_counter=prg_counter+1\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(annotations, f)\n",
    "# Read txt files containing bounding boxes (ground truth and detections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(annotations, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import timeit\n",
    "from dataset import *\n",
    "import torchvision.ops.boxes as nms_box\n",
    "import helper as helper\n",
    "import test as tester\n",
    "from utils import *\n",
    "from BoundingBox import BoundingBox\n",
    "from BoundingBoxes import BoundingBoxes\n",
    "import json\n",
    "\n",
    "net = Darknet(\"../cfg/yolov3.cfg\")\n",
    "inp_dim=net.inp_dim\n",
    "pw_ph=net.pw_ph.cuda()\n",
    "cx_cy=net.cx_cy.cuda()\n",
    "stride=net.stride.cuda()\n",
    "\n",
    "start_time = time.time()\n",
    "'''\n",
    "when loading weights from dataparallel model then, you first need to instatiate the dataparallel model \n",
    "if you start fresh then first model.load_weights and then make it parallel\n",
    "'''\n",
    "try:\n",
    "    PATH = '../pth/yolo201sds7/yolo2017_best.pth'\n",
    "    weights = torch.load(PATH)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "\n",
    "    if torch.cuda.device_count() > 2:\n",
    "        print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(net)\n",
    "    else:\n",
    "        model=net\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(weights)\n",
    "    model.eval()\n",
    "except FileNotFoundError: \n",
    "    net.load_weights(\"../yolov3.weights\")\n",
    "    print('orginal weights loaded')\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net.to(device)\n",
    "    \n",
    "\n",
    "    \n",
    "net.train()\n",
    "\n",
    "subset=0.0006\n",
    "coco_version='2014'\n",
    "confidence=0.1\n",
    "iou_threshold=0.5\n",
    "\n",
    "\n",
    "max_detections=100\n",
    "transformed_dataset=Coco(partition='val',coco_version=coco_version,subset=subset,\n",
    "                                           transform=transforms.Compose([\n",
    "                                            ResizeToTensor(inp_dim)\n",
    "                                           ]))\n",
    "\n",
    "\n",
    "\n",
    "dataset_len=(len(transformed_dataset))\n",
    "# print(dataset_len)\n",
    "print('Length of dataset is '+ str(dataset_len)+'\\n')\n",
    "batch_size=8\n",
    "\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=batch_size,\n",
    "                        shuffle=False,collate_fn=helper.my_collate, num_workers=4)\n",
    "\n",
    "\n",
    "for images,targets,img_name in dataloader:\n",
    "    inp=images.cuda()\n",
    "    raw_pred = net(inp, torch.cuda.is_available())\n",
    "    targets,anchors,offset,strd,mask=helper.collapse_boxes(targets,pw_ph,cx_cy,stride)\n",
    "\n",
    "    raw_pred=raw_pred.to(device='cuda')\n",
    "    true_pred=util.transform(raw_pred.clone(),pw_ph,cx_cy,stride)\n",
    "    sorted_pred=torch.sort(true_pred[:,:,4]*(true_pred[:,:,5:].max(axis=2)[0]),descending=True)\n",
    "    pred_mask=sorted_pred[0]>confidence\n",
    "    indices=[(sorted_pred[1][e,:][pred_mask[e,:]]) for e in range(pred_mask.shape[0])]\n",
    "    pred_final=[true_pred[i,indices[i],:] for i in range(len(indices))]\n",
    "    pred_final_coord=[util.get_abs_coord(pred_final[i].unsqueeze(-2)) for i in range(len(pred_final))]\n",
    "    \n",
    "    indices=[nms_box.nms(pred_final_coord[i][0],pred_final[i][:,4],iou_threshold) for i in range(len(pred_final))]\n",
    "\n",
    "    pred_final=[pred_final[i][indices[i],:] for i in range(len(pred_final))]\n",
    "    \n",
    "    abs_pred_final=[helper.convert2_abs_xywh(pred_final[i],img_name[i]['img_size'],inp_dim) for i in range(len(pred_final))]\n",
    "    \n",
    "    break\n",
    "    \n",
    "#     pred_final[:,0:4]=pred_final[:,0:4]/inp_dim\n",
    "    helper.write_pred(img_name,pred_final,inp_dim,max_detections,coco_version)\n",
    "\n",
    "\n",
    "\n",
    "a=tester.evaluate(net, 'cpu',coco_version='2014',confidence=0.1,iou_threshold=0.5,subset=0.0003)\n",
    "\n",
    "# a=tester.get_map(model, confidence=0.1,iou_threshold=0.5,coco_version='2014',subset=0.0003)\n",
    "\n",
    "\n",
    "# print(a)\n",
    "# subset=0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tester.evaluate(net, 'cpu',coco_version='2014',confidence=0.01,iou_threshold=0.5,subset=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(targets.shape)\n",
    "targets_list=[targets[:13,:],targets[13:,:]]\n",
    "abs_targets=[helper.convert2_abs_xywh(targets_list[i],img_name[i]['img_size'],1) for i in range(len(targets_list))]\n",
    "print(abs_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>More efficient Yolo</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.0001, 'epochs': 90, 'resume_from': 0, 'coco_version': '2017', 'batch_size': 8, 'weight_decay': 0.0005, 'momentum': 0.9, 'optimizer': 'sgd', 'alpha': 0.9, 'gamma': 0, 'lcoord': 5, 'lno_obj': 0.5, 'iou_type': (1, 0, 0), 'iou_ignore_thresh': 0.213, 'tfidf': True, 'idf_weights': True, 'tfidf_col_names': ['img_freq', 'none', 'none', 'none', 'no_softmax'], 'inf_confidence': 0.01, 'inf_iou_threshold': 0.5, 'augment': 1, 'workers': 4, 'pretrained': False, 'path': 'yolo2017', 'reduction': 'sum'}\n",
      "Using:  cuda:0\n",
      "Pgr:0.8186516125731242% L:7.840477466583252 IoU:0.7468103170394897 pob:0.2061162143945694 nob:0.006857478525489569 PCls:0.5595539808273315 ncls:0.00557526666671037795755"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-085e50c33379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0moutcome\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myolo_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0mmAP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoco_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inf_confidence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miou_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inf_iou_threshold'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmAP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data1/users/konsa15/workspace/notebooks/coco/yolo/yolo_function.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, optimizer, dataloader, hyperparameters, mode)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mraw_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m                 \u001b[0mbreak_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dataset import *\n",
    "import timeit \n",
    "import cv2\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "from darknet import *\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import test as tester\n",
    "import sys\n",
    "import timeit\n",
    "import torch.autograd\n",
    "import helper as helper\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "import yolo_function as yolo_function\n",
    "\n",
    "\n",
    "hyperparameters={'lr': 0.0001, \n",
    "                 'epochs': 90,\n",
    "                 'resume_from':0,\n",
    "                 'coco_version': '2017', #can be either '2014' or '2017'\n",
    "                 'batch_size': 8,\n",
    "                 'weight_decay': 0.0005,\n",
    "                 'momentum': 0.9, \n",
    "                 'optimizer': 'sgd', \n",
    "                 'alpha': 0.9, \n",
    "                 'gamma': 0, \n",
    "                 'lcoord': 5,\n",
    "                 'lno_obj': 0.5,\n",
    "                 'iou_type': (1, 0, 0),\n",
    "                 'iou_ignore_thresh': 0.213, \n",
    "                 'tfidf': True, \n",
    "                 'idf_weights': True, \n",
    "                 'tfidf_col_names': ['img_freq', 'none', 'none', 'none', 'no_softmax'],\n",
    "                 'inf_confidence':0.01,\n",
    "                 'inf_iou_threshold':0.5,\n",
    "                 'augment': 1, \n",
    "                 'workers': 4,\n",
    "                 'pretrained':False,\n",
    "                 'path': 'yolo2017', \n",
    "                 'reduction': 'sum'}\n",
    "\n",
    "mode={'bayes_opt':False,\n",
    "      'debugging':False,\n",
    "      'show_output':True,\n",
    "      'multi_gpu':False,\n",
    "      'show_temp_summary':False,\n",
    "      'save_summary': True\n",
    "     }\n",
    "\n",
    "print(hyperparameters)\n",
    "if isinstance(hyperparameters['idf_weights'],pd.DataFrame)==False:\n",
    "    if (hyperparameters['idf_weights']==True):\n",
    "        hyperparameters['idf_weights']=pd.read_csv('../idf.csv')\n",
    "    else:\n",
    "        hyperparameters['idf_weights']=False\n",
    "    \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using: ',device)\n",
    "\n",
    "net = Darknet(\"../cfg/yolov3.cfg\")\n",
    "coco_version=hyperparameters['coco_version']\n",
    "inp_dim=net.inp_dim\n",
    "\n",
    "'''\n",
    "when loading weights from dataparallel model then, you first need to instatiate the dataparallel model \n",
    "if you start fresh then first model.load_weights and then make it parallel\n",
    "'''\n",
    "try:\n",
    "    PATH = '../pth/'+hyperparameters['path']+'/'\n",
    "    checkpoint = torch.load(PATH+hyperparameters['path']+'.tar')\n",
    "                    # Assuming that we https://pytorch.org/docs/stable/data.html#torch.utils.data.Datasetare on a CUDA machine, this should print a CUDA device:\n",
    "    net.to(device)\n",
    "\n",
    "    if (torch.cuda.device_count() > 1)&(mode['multi_gpu']==True):\n",
    "        model = nn.DataParallel(net)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.to(device)\n",
    "    else:\n",
    "        model=net\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.to(device)\n",
    "\n",
    "    if hyperparameters['optimizer']=='sgd':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=hyperparameters['lr'], weight_decay=hyperparameters['weight_decay'], momentum=hyperparameters['momentum'])\n",
    "    elif hyperparameters['optimizer']=='adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=hyperparameters['lr'], weight_decay=hyperparameters['weight_decay'])\n",
    "\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    hyperparameters['resume_from']=checkpoint['epoch']\n",
    "\n",
    "except FileNotFoundError:\n",
    "    if (hyperparameters['pretrained']==True):\n",
    "        print(\"WARNING FILE NOT FOUND INSTEAD USING OFFICIAL PRETRAINED\")\n",
    "        net.load_weights(\"../yolov3.weights\")\n",
    "\n",
    "        net.to(device)\n",
    "        if (torch.cuda.device_count() > 1)&(mode['multi_gpu']==True):\n",
    "            model = nn.DataParallel(net)\n",
    "            model.to(device)\n",
    "        else:\n",
    "            model=net\n",
    "\n",
    "        if hyperparameters['optimizer']=='sgd':\n",
    "            optimizer = optim.SGD(model.parameters(), lr=hyperparameters['lr'], weight_decay=hyperparameters['weight_decay'], momentum=hyperparameters['momentum'])\n",
    "        elif hyperparameters['optimizer']=='adam':\n",
    "            optimizer = optim.Adam(model.parameters(), lr=hyperparameters['lr'], weight_decay=hyperparameters['weight_decay'])\n",
    "        hyperparameters['resume_from']=0\n",
    "    else:\n",
    "        try:\n",
    "            PATH = '../pth/'+hyperparameters['path']+'/'\n",
    "            os.mkdir(PATH)\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "#                     print('path already exist')\n",
    "\n",
    "        if (torch.cuda.device_count() > 1)&(mode['multi_gpu']==True):\n",
    "            model = nn.DataParallel(net)\n",
    "            model.to(device)\n",
    "        else:\n",
    "            model=net\n",
    "            model.to(device)\n",
    "\n",
    "        if hyperparameters['optimizer']=='sgd':\n",
    "            optimizer = optim.SGD(model.parameters(), lr=hyperparameters['lr'], weight_decay=hyperparameters['weight_decay'], momentum=hyperparameters['momentum'])\n",
    "        elif hyperparameters['optimizer']=='adam':\n",
    "            optimizer = optim.Adam(model.parameters(), lr=hyperparameters['lr'], weight_decay=hyperparameters['weight_decay'])\n",
    "        hyperparameters['resume_from']=0\n",
    "    \n",
    "    \n",
    "if(mode['show_temp_summary']==True):\n",
    "    writer = SummaryWriter('../results/test_vis/')\n",
    "\n",
    "\n",
    "\n",
    "if hyperparameters['augment']>0:\n",
    "    train_dataset=Coco(partition='train',coco_version=coco_version,transform=transforms.Compose([Augment(hyperparameters['augment']),ResizeToTensor(inp_dim)]))\n",
    "else:\n",
    "    train_dataset=Coco(partition='train',coco_version=coco_version,transform=transforms.Compose([ResizeToTensor(inp_dim)]))\n",
    "    \n",
    "dataset_len=(len(train_dataset))\n",
    "batch_size=hyperparameters['batch_size']\n",
    "mAP_best=0\n",
    "\n",
    "scheduler=optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max',patience=5)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                            shuffle=True,collate_fn=helper.collate_fn, num_workers=hyperparameters['workers'])\n",
    "\n",
    "\n",
    "for i in range(hyperparameters['epochs']):\n",
    "    outcome=yolo_function.train_one_epoch(model,optimizer,train_dataloader,hyperparameters,mode)\n",
    "    mAP=test.evaluate(model, device,coco_version,confidence=hyperparameters['inf_confidence'],iou_threshold=hyperparameters['inf_iou_threshold'])\n",
    "    scheduler.step(mAP)\n",
    "    if(mode['save_summary']==True):\n",
    "        writer = SummaryWriter('../results/'+hyperparameters['path'])\n",
    "        writer.add_scalar('Loss/train', outcome['avg_loss'], hyperparameters['resume_from'])\n",
    "        writer.add_scalar('AIoU/train', outcome['avg_iou'], hyperparameters['resume_from'])\n",
    "        writer.add_scalar('PConf/train', outcome['avg_conf'], hyperparameters['resume_from'])\n",
    "        writer.add_scalar('NConf/train', outcome['avg_no_conf'], hyperparameters['resume_from'])\n",
    "        writer.add_scalar('PClass/train', outcome['avg_pos'], hyperparameters['resume_from'])\n",
    "        writer.add_scalar('NClass/train', outcome['avg_neg'], hyperparameters['resume_from'])\n",
    "        \n",
    "        writer.add_scalar('mAP/valid', mAP, hyperparameters['resume_from'])\n",
    "\n",
    "    torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'avg_loss': outcome['total_loss'],\n",
    "            'avg_iou': outcome['avg_iou'],\n",
    "            'avg_pos': outcome['avg_pos'],\n",
    "            'avg_neg':outcome['avg_neg'],\n",
    "            'avg_conf': outcome['avg_conf'],\n",
    "            'avg_no_conf': outcome['avg_no_conf'],\n",
    "            'epoch':hyperparameters['resume_from']+1,\n",
    "            'mAP': mAP\n",
    "            }, PATH+hyperparameters['path']+'.tar')\n",
    "\n",
    "        \n",
    "    if mAP>mAP_best:\n",
    "        torch.save(checkpoint, PATH+hyperparameters['path']+'_best.tar')\n",
    "        mAP_best=mAP\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "'model_state_dict': model.state_dict(),\n",
    "'optimizer_state_dict': optimizer.state_dict(),\n",
    "'avg_loss': 0,\n",
    "'avg_iou': 0,\n",
    "'avg_pos': 0,\n",
    "'avg_neg':0,\n",
    "'avg_conf': 0,\n",
    "'avg_no_conf': 0,\n",
    "'epoch':hyperparameters['resume_from']\n",
    "}, PATH+hyperparameters['path']+'.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters['idf_weights']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "import timeit \n",
    "import cv2\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import timeit\n",
    "import torch.autograd\n",
    "import helper as helper\n",
    "import pandas as pd\n",
    "from torch import autograd\n",
    "import test as tester\n",
    "import yolo_function\n",
    "\n",
    "\n",
    "\n",
    "net = Darknet(\"../cfg/yolov3.cfg\")\n",
    "inp_dim=net.inp_dim\n",
    "pw_ph=net.pw_ph.to(device='cuda')\n",
    "cx_cy=net.cx_cy.to(device='cuda')\n",
    "stride=net.stride.to(device='cuda')\n",
    "print('YOLO version2')\n",
    "\n",
    "hyperparameters={'lr': 0.00001, \n",
    "                 'epochs': 90,\n",
    "                 'resume_from':15,\n",
    "                 'coco_version': '2017', #can be either '2014' or '2017'\n",
    "                 'batch_size': 8,\n",
    "                 'weight_decay': 0.0005,\n",
    "                 'momentum': 0.9, \n",
    "                 'optimizer': 'sgd', \n",
    "                 'alpha': 0.5, \n",
    "                 'gamma': 0, \n",
    "                 'lcoord': 1,\n",
    "                 'lno_obj': 0.5,\n",
    "                 'iou_type': (1, 0, 0),\n",
    "                 'iou_ignore_thresh': 0.5, \n",
    "                 'tfidf': False, \n",
    "                 'idf_weights': True, \n",
    "                 'tfidf_col_names': ['img_freq', 'none', 'none', 'none', 'no_softmax'],\n",
    "                 'inf_confidence':0.01,\n",
    "                 'inf_iou_threshold':0.5,\n",
    "                 'augment': 0, \n",
    "                 'workers': 0, \n",
    "                 'path': 'yolo2017', \n",
    "                 'reduction': 'sum'}\n",
    "\n",
    "\n",
    "bayes_opt=True\n",
    "mode={'bayes_opt':bayes_opt,\n",
    "      'debugging':False,\n",
    "      'show_output':True,\n",
    "      'multi_gpu':False,\n",
    "      'show_temp_summary':False,\n",
    "      'save_summary': bayes_opt==False\n",
    "     }\n",
    "\n",
    "print(hyperparameters)\n",
    "coco_version=hyperparameters['coco_version']\n",
    "if (hyperparameters['idf_weights']==True):\n",
    "    hyperparameters['idf_weights']=pd.read_csv('../idf.csv')\n",
    "else:\n",
    "    hyperparameters['idf_weights']=False\n",
    "        \n",
    "'''\n",
    "when loading weights from dataparallel model then, you first need to instatiate the dataparallel model \n",
    "if you start fresh then first model.load_weights and then make it parallel\n",
    "'''\n",
    "try:\n",
    "    PATH = '../pth/'+hyperparameters['path']+'/'\n",
    "    weights = torch.load(PATH+hyperparameters['path']+'_best.pth')\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we https://pytorch.org/docs/stable/data.html#torch.utils.data.Datasetare on a CUDA machine, this should print a CUDA device:\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "\n",
    "    if (torch.cuda.device_count() > 2):\n",
    "        print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(net)\n",
    "        model.to(device)\n",
    "        model.load_state_dict(weights)\n",
    "    else:\n",
    "        model=net\n",
    "        model.to(device)\n",
    "        model.load_state_dict(weights)\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    try:\n",
    "        os.mkdir(PATH)\n",
    "    except FileExistsError:\n",
    "        print('path already exist')\n",
    "    net.load_weights(\"../yolov3.weights\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "    if (torch.cuda.device_count() > 2):\n",
    "        print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(net)\n",
    "        model.to(device)\n",
    "    else:\n",
    "        model=net\n",
    "        \n",
    "if hyperparameters['augment']>0:\n",
    "    transformed_dataset=Coco(partition='train',coco_version=coco_version,subset=0.001,transform=transforms.Compose([Augment(hyperparameters['augment']),ResizeToTensor(inp_dim)]))\n",
    "else:\n",
    "    transformed_dataset=Coco(partition='train',coco_version=coco_version,subset=0.001,transform=ResizeToTensor(inp_dim))\n",
    "    \n",
    "\n",
    "\n",
    "dataset_len=(len(transformed_dataset))\n",
    "print('Length of dataset is '+ str(dataset_len)+'\\n')\n",
    "batch_size=hyperparameters['batch_size']\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=batch_size,\n",
    "                        shuffle=True,collate_fn=helper.collate_fn, num_workers=hyperparameters['workers'])\n",
    "\n",
    "\n",
    "if hyperparameters['optimizer']=='sgd':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=hyperparameters['lr'], weight_decay=hyperparameters['weight_decay'], momentum=hyperparameters['momentum'])\n",
    "elif hyperparameters['otimizer']=='adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hyperparameters['lr'], weight_decay=hyperparameters['weight_decay'])\n",
    "\n",
    "    \n",
    "outcome=yolo_function.train_one_epoch(model,optimizer,dataloader,hyperparameters,mode)\n",
    "tester.evaluate(model, device,coco_version,confidence=0.01,iou_threshold=0.5,subset=0.01)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
