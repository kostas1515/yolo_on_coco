{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import torch\n",
    "import helper as helper\n",
    "from dataset import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path='../labels/coco/labels/val2017/000000007108.txt'\n",
    "with open(label_path) as box:\n",
    "    box=box.read()\n",
    "    box=pd.DataFrame([x.split() for x in box.rstrip('\\n').split('\\n')],columns=['class','xc','yc','w','h'])\n",
    "\n",
    "b= box.values.astype(np.float32)\n",
    "bboxes=b\n",
    "b=torch.tensor(b)\n",
    "labels = b.T[0].reshape(b.shape[0], 1)\n",
    "one_hot_target = (labels == torch.arange(80).reshape(1, 80)).float()\n",
    "conf=torch.ones([b.shape[0],1])\n",
    "boxes=torch.cat((b.T[1:],conf.T,one_hot_target.T)).T\n",
    "\n",
    "img_path='../images/val2017/000000007108.jpg'\n",
    "img=cv2.imread(img_path)[:,:,::-1] \n",
    "\n",
    "sample={'images': img,\n",
    "        'boxes': boxes}\n",
    "\n",
    "(h,w,c)=img.shape\n",
    "\n",
    "bboxes[:,1]=bboxes[:,1]*w\n",
    "bboxes[:,2]=bboxes[:,2]*h\n",
    "bboxes[:,3]=bboxes[:,3]*w\n",
    "bboxes[:,4]=bboxes[:,4]*h\n",
    "bboxes[:,1]=bboxes[:,1]-bboxes[:,3]/2\n",
    "bboxes[:,2]=bboxes[:,2]-bboxes[:,4]/2\n",
    "bboxes[:,3]=bboxes[:,1]+bboxes[:,3]\n",
    "bboxes[:,4]=bboxes[:,2]+bboxes[:,4]\n",
    "print(bboxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import parameters as iap\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
    "\n",
    "\n",
    "image = sample['images']\n",
    "\n",
    "bbs = BoundingBoxesOnImage([\n",
    "    BoundingBox(x1=b[1], y1=b[2], x2=b[3], y2=b[4], label=b[0]) for b in bboxes], shape=image.shape)\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.LinearContrast(alpha=(0.1, 1.9)),\n",
    "    iaa.ShearX((-30, 30)),\n",
    "    # Small gaussian blur with random sigma between 0 and 0.5.\n",
    "    # But we only blur about 50% of all images.\n",
    "    iaa.Grayscale(alpha=(0.1, 0.9)),\n",
    "    iaa.Sometimes(\n",
    "        0.5,\n",
    "        iaa.HistogramEqualization(),\n",
    "        iaa.GaussianBlur(sigma=(0, 0.5))\n",
    "    ),\n",
    "    iaa.Solarize(0.5, threshold=(0, 256)),\n",
    "    # Strengthen or weaken the contrast in each image.\n",
    "    # Add gaussian noise.\n",
    "    # For 50% of all images, we sample the noise once per pixel.\n",
    "    # For the other 50% of all images, we sample the noise per pixel AND\n",
    "    # channel. This can change the color (not only brightness) of the\n",
    "    # pixels.\n",
    "    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),\n",
    "    # Make some images brighter and some darker.\n",
    "    # In 20% of all cases, we sample the multiplier once per channel,\n",
    "    # which can end up changing the color of the images.\n",
    "    iaa.Multiply((0.8, 1.2), per_channel=0.2),\n",
    "    # Apply affine transformations to each image.\n",
    "    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
    "    iaa.Affine(\n",
    "        translate_px={\"x\": (-150, 150)},\n",
    "        rotate=(-30, 30)\n",
    "    )\n",
    "], random_order=True)\n",
    "\n",
    "# Augment BBs and images.\n",
    "image_aug, bbs_aug = seq(image=image, bounding_boxes=bbs)\n",
    "\n",
    "# print coordinates before/after augmentation (see below)\n",
    "# use .x1_int, .y_int, ... to get integer coordinates\n",
    "for i in range(len(bbs.bounding_boxes)):\n",
    "    before = bbs.bounding_boxes[i]\n",
    "    after = bbs_aug.bounding_boxes[i]\n",
    "    print(\"BB %d: (%.4f, %.4f, %.4f, %.4f) -> (%.4f, %.4f, %.4f, %.4f)\" % (\n",
    "        i,\n",
    "        before.x1, before.y1, before.x2, before.y2,\n",
    "        after.x1, after.y1, after.x2, after.y2)\n",
    "    )\n",
    "\n",
    "# image with BBs before/after augmentation (shown below)\n",
    "# image_before = bbs.draw_on_image(image, size=2)\n",
    "# image_after = bbs_aug.draw_on_image(image_aug, size=2, color=[0, 0, 255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bboxes=bbs_aug.to_xyxy_array()\n",
    "bbs_aug=bbs_aug.remove_out_of_image()\n",
    "\n",
    "ia.imshow(bbs_aug.draw_on_image(image_aug, size=2))\n",
    "\n",
    "labels=np.array([[box.label for box in bbs_aug.bounding_boxes]]).T\n",
    "new_bboxes=bbs_aug.to_xyxy_array()\n",
    "np.hstack((labels,new_bboxes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ia.imshow(bbs.draw_on_image(image, size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box=open(\"../detections/000000007108.txt\")\n",
    "box=box.read()\n",
    "box=pd.DataFrame([x.split() for x in box.rstrip('\\n').split('\\n')],columns=['class','conf','xc','yc','w','h'])\n",
    "b= box.values.astype(np.float32)\n",
    "b=torch.tensor(b)\n",
    "labels = b.T[0].reshape(b.shape[0], 1)\n",
    "objectness = b.T[1].reshape(b.shape[0], 1)\n",
    "one_hot_target = (labels == torch.arange(80).reshape(1, 80)).float()\n",
    "# conf=torch.ones([b.shape[0],1])\n",
    "\n",
    "boxes=torch.cat((b.T[2:],objectness.T,one_hot_target.T)).T\n",
    "print(boxes.shape)\n",
    "# plt.imshow(draw_rect(sample['images'], boxes))\n",
    "# plt.savefig('elephants.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.ops.boxes as nms_box\n",
    "import util as util\n",
    "abs_boxes=util.get_abs_coord(boxes[:,0:4].unsqueeze(0)).squeeze(1)\n",
    "print(abs_boxes.shape)\n",
    "fb=nms_box.nms(abs_boxes,boxes[:,4].cuda(),0.5)\n",
    "print(nms_box.box_iou(abs_boxes,abs_boxes))\n",
    "print(fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=torch.tensor([[15.0,25.0,30.0,50.0],[20.0,30.0,40.0,50.0]])\n",
    "test2=torch.tensor([[15.0,25.0,35.0,45.0],[20.0,30.0,40.0,50.0]])\n",
    "\n",
    "fb=nms_box.nms(test1,torch.tensor([0.9,0.9]),0.3)\n",
    "print(nms_box.box_iou(boxes[:,0:4],boxes[:,0:4]))\n",
    "print(fb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff=1\n",
    "import random\n",
    "print(random.uniform(1,2))\n",
    "def shear(sample):\n",
    "    \n",
    "    img=sample['images']\n",
    "    bboxes=sample['boxes']\n",
    "    shear_factor = 0.6\n",
    "\n",
    "    w,h = img.shape[1], img.shape[0]\n",
    "    \n",
    "    if shear_factor < 0:\n",
    "        sample = RandomHorizontalFlip(-1)(sample)\n",
    "        img=sample['images']\n",
    "        bboxes=sample['boxes']\n",
    "\n",
    "    \n",
    "    M = np.array([[1, abs(shear_factor), 0],[0,1,0]])\n",
    "\n",
    "    nW =  img.shape[1] + abs(shear_factor*img.shape[0])\n",
    "\n",
    "    bboxes[:,0] += bboxes[:,1]* abs(torch.tan(torch.tensor([shear_factor])))\n",
    "    bboxes[:,2] += bboxes[:,3]* abs(torch.tan(torch.tensor([shear_factor])))\n",
    "    \n",
    "\n",
    "\n",
    "    img = cv2.warpAffine(img, M, (int(nW), img.shape[0]))\n",
    "\n",
    "\n",
    "#     if shear_factor < 0:\n",
    "#         sample = RandomHorizontalFlip(-1)(sample)\n",
    "#         img=sample['images']\n",
    "#         bboxes=sample['boxes']\n",
    "#         print(bboxes)\n",
    "#     plt.imshow(draw_rect(img, bboxes))\n",
    "\n",
    "    img = cv2.resize(img, (w,h))\n",
    "\n",
    "    scale_factor_x = nW / w\n",
    "    print(scale_factor_x)\n",
    "    bboxes[:,:4] /= torch.tensor([scale_factor_x, 1, scale_factor_x, 1])\n",
    "    print(bboxes)\n",
    "    return img, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, bboxes = shear(sample)\n",
    "\n",
    "plt.imshow(draw_rect(img, bboxes))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import pickle as pkl\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_rect(im, cords, color = None):\n",
    "    \"\"\"Draw the rectangle on the image\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    im : numpy.ndarray\n",
    "        numpy image \n",
    "    \n",
    "    cords: numpy.ndarray\n",
    "        Numpy array containing bounding boxes of shape `N X 4` where N is the \n",
    "        number of bounding boxes and the bounding boxes are represented in the\n",
    "        format `x1 y1 x2 y2`\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    numpy.ndarray\n",
    "        numpy image with bounding boxes drawn on it\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    im = im.copy()\n",
    "    h=im.shape[0]\n",
    "    w=im.shape[1]\n",
    "    cords[:,0]=cords[:,0]*w\n",
    "    cords[:,1]=cords[:,1]*h\n",
    "    cords[:,2]=cords[:,2]*w\n",
    "    cords[:,3]=cords[:,3]*h\n",
    "    if not color:\n",
    "        color = [255,255,255]\n",
    "    for cord in cords:\n",
    "        pt1, pt2 = (cord[0]-cord[2]/2, cord[1]-cord[3]/2) , (cord[0]+cord[2]/2, cord[1]+cord[3]/2)\n",
    "        \n",
    "#         pt1, pt2 = (cord[0], cord[1]) , (cord[2], cord[3])\n",
    "        \n",
    "        pt1 = int(pt1[0]), int(pt1[1])\n",
    "        pt2 = int(pt2[0]), int(pt2[1])\n",
    "    \n",
    "        im = cv2.rectangle(im.copy(), pt1, pt2, color, int(max(im.shape[:2])/200))\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "translate=RandomTranslate()\n",
    "flip=RandomVerticalFlip()\n",
    "\n",
    "rotate = RandomRotate(20) \n",
    "sample=flip(sample)\n",
    "sample=translate(sample)\n",
    "sample = rotate(sample)\n",
    "\n",
    "plt.imshow(draw_rect(img, bboxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, bboxes = rotate(sample)\n",
    "\n",
    "plt.imshow(draw_rect(img, bboxes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(helper.get_corners(bboxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a=torch.tensor([[[1,2,2,4,0,0,0,1],[2,3,5,3,0,0,1,0]]])\n",
    "print(a.shape)\n",
    "b=((a[:,:,4:]==1).nonzero())\n",
    "b=b[:,-1].unsqueeze(0).unsqueeze(-1)\n",
    "print(b.shape)\n",
    "new=a[:,:,:4]\n",
    "print(new.shape)\n",
    "new=torch.cat((new.T,b.T)).T\n",
    "print(new)\n",
    "sorted_pred=torch.sort(new[0,:,4],descending=False)\n",
    "print(sorted_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = box.values.astype(np.float32)\n",
    "b=torch.tensor(b)\n",
    "labels = b.T[0].reshape(b.shape[0], 1)\n",
    "one_hot_target = (labels == torch.arange(80).reshape(1, 80)).float()\n",
    "conf=torch.ones([b.shape[0],1])\n",
    "boxes=torch.cat((b.T[1:],conf.T,one_hot_target.T)).T\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name='images/train2017.zip'\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    image=zip.read('train2017/000000408542.jpg')\n",
    "    img = cv2.imdecode(np.frombuffer(image, np.uint8),1)\n",
    "    im_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    io.imshow(im_rgb)\n",
    "    io.imsave('fig.png',im_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('pointers/train2017.txt',names=['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['box']=df['filename'].apply(lambda x: 'coco/labels/'+x.split('.')[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['box']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.0001, 'batch_size': 16, 'weight_decay': 0.001, 'momentum': 0.9, 'optimizer': 'sgd', 'alpha': 0.5, 'gamma': 0, 'lcoord': 5, 'lno_obj': 1, 'iou_type': (1, 0, 0), 'iou_ignore_thresh': 0.5, 'tfidf': True, 'idf_weights': True, 'tfidf_col_names': ['obj_freq', 'obj_freq', 'obj_freq', 'obj_freq', 'softmax'], 'augment': False, 'workers': 4, 'path': 'tes_iou', 'reduction': 'sum'}\n",
      "cuda:0\n",
      "Using  2 GPUs!\n",
      "Length of dataset is 118287\n",
      "\n",
      "\n",
      " epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/konsa15/.conda/envs/faster_rcnn/lib/python3.8/site-packages/torch/nn/functional.py:2503: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\"Default upsampling behavior when mode={} is changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pgr:3.922662676371875% L:2.475751278524398 IoU:0.7354631423950195 pob:0.4225219786167145 nob:0.0005686893709935248 PCls:0.9350520968437195 ncls:0.000822125235572457356247"
     ]
    }
   ],
   "source": [
    "from dataset import *\n",
    "import timeit \n",
    "import cv2\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import test as tester\n",
    "import sys\n",
    "import timeit\n",
    "import torch.autograd\n",
    "import helper as helper\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "net = Darknet(\"../cfg/yolov3.cfg\")\n",
    "inp_dim=net.inp_dim\n",
    "pw_ph=net.pw_ph.to(device='cuda')\n",
    "cx_cy=net.cx_cy.to(device='cuda')\n",
    "stride=net.stride.to(device='cuda')\n",
    "\n",
    "\n",
    "hyperparameters={'lr':0.0001,\n",
    "                 'batch_size':16,\n",
    "                 'weight_decay':0.001,\n",
    "                 'momentum':0.9,\n",
    "                 'optimizer':'sgd',\n",
    "                 'alpha':0.5,\n",
    "                 'gamma':0,\n",
    "                 'lcoord':5,\n",
    "                 'lno_obj':1,\n",
    "                 'iou_type':(1,0,0),#(GIoU,DIoU,CIoU) default is 0,0,0 for iou\n",
    "                 'iou_ignore_thresh':0.5,\n",
    "                 'tfidf':True,\n",
    "                 'idf_weights':True,\n",
    "                 'tfidf_col_names':['obj_freq','obj_freq','obj_freq','obj_freq','softmax'], #default is ['obj_freq/img_freq','area','xc','yc','softmax']-->[class_weights,scale_weights,xweights,yweights,softmax/no_softmax]\n",
    "                 'augment':False,\n",
    "                 'workers':4,\n",
    "                 'path':'tes_iou',\n",
    "                 'reduction':'sum'}\n",
    "\n",
    "print(hyperparameters)\n",
    "\n",
    "if (hyperparameters['idf_weights']==True):\n",
    "    hyperparameters['idf_weights']=pd.read_csv('../idf.csv')\n",
    "else:\n",
    "    hyperparameters['idf_weights']=False\n",
    "        \n",
    "'''\n",
    "when loading weights from dataparallel model then, you first need to instatiate the dataparallel model \n",
    "if you start fresh then first model.load_weights and then make it parallel\n",
    "'''\n",
    "try:\n",
    "    PATH = '../'+hyperparameters['path']\n",
    "    weights = torch.load(PATH)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we https://pytorch.org/docs/stable/data.html#torch.utils.data.Datasetare on a CUDA machine, this should print a CUDA device:\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "\n",
    "    if (torch.cuda.device_count() > 1):\n",
    "        print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(net)\n",
    "        model.to(device)\n",
    "        model.load_state_dict(weights)\n",
    "    else:\n",
    "        model=net\n",
    "        model.to(device)\n",
    "        model.load_state_dict(weights)\n",
    "        \n",
    "except FileNotFoundError: \n",
    "    net.load_weights(\"../yolov3.weights\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "    if (torch.cuda.device_count() > 1):\n",
    "        print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(net)\n",
    "        model.to(device)\n",
    "    else:\n",
    "        model=net\n",
    "        \n",
    "if hyperparameters['augment']==True:\n",
    "    transformed_dataset=Coco(partition='train',transform=transforms.Compose([Augment(),ResizeToTensor(inp_dim)]))\n",
    "else:\n",
    "    transformed_dataset=Coco(partition='train',transform=transforms.Compose([ResizeToTensor(inp_dim)]))\n",
    "    \n",
    "\n",
    "\n",
    "writer = SummaryWriter('../results/'+hyperparameters['path'])\n",
    "dataset_len=(len(transformed_dataset))\n",
    "print('Length of dataset is '+ str(dataset_len)+'\\n')\n",
    "batch_size=hyperparameters['batch_size']\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=batch_size,\n",
    "                        shuffle=True,collate_fn=helper.my_collate, num_workers=hyperparameters['workers'])\n",
    "\n",
    "\n",
    "if hyperparameters['optimizer']=='sgd':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=hyperparameters['lr'], weight_decay=hyperparameters['weight_decay'], momentum=hyperparameters['momentum'])\n",
    "elif hyperparameters['otimizer']=='adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hyperparameters['lr'], weight_decay=hyperparameters['weight_decay'])\n",
    "\n",
    "lambda1 = lambda epoch: 0.95**epoch\n",
    "scheduler=optim.lr_scheduler.LambdaLR(optimizer, lambda1, last_epoch=-1)\n",
    "mAP_max=0\n",
    "epochs=50\n",
    "total_loss=0\n",
    "write=0\n",
    "misses=0\n",
    "avg_iou=0\n",
    "for e in range(epochs):\n",
    "    prg_counter=0\n",
    "    train_counter=0\n",
    "    total_loss=0\n",
    "    avg_iou=0\n",
    "    avg_infs=0\n",
    "    avg_conf=0\n",
    "    avg_no_conf=0\n",
    "    avg_pos=0\n",
    "    avg_neg=0\n",
    "    print(\"\\n epoch \"+str(e))\n",
    "    misses=0\n",
    "    for images,targets,img_names in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        targets,anchors,offset,strd,mask=helper.collapse_boxes(targets,pw_ph,cx_cy,stride)\n",
    "        images=images.cuda()\n",
    "        raw_pred = model(images, torch.cuda.is_available())\n",
    "        raw_pred=helper.expand_predictions(raw_pred,mask)\n",
    "        true_pred=util.transform(raw_pred.clone(),anchors,offset,strd)\n",
    "        targets=targets.unsqueeze(-3)\n",
    "        targets=targets.cuda()\n",
    "        iou_mask,noobj_mask=util.get_responsible_masks(true_pred,targets,offset,strd,mask,inp_dim,hyperparameters)\n",
    "        iou1=torch.diag(util.bbox_iou(util.get_abs_coord(true_pred[iou_mask.T,:].unsqueeze(-3)),util.transpose_target(get_abs_coord(targets)*inp_dim),hyperparameters['iou_type']))\n",
    "        iou=iou1.mean().item()\n",
    "        noobj_box=raw_pred[:,:,4:5].clone()\n",
    "        noobj_box=helper.uncollapse(noobj_box,mask)\n",
    "        noobj_mask=helper.uncollapse(noobj_mask.T.unsqueeze(-1),mask)\n",
    "        \n",
    "        \n",
    "        conf=raw_pred[iou_mask.T,:][:,4:5].mean().item()\n",
    "        class_mask=targets[:,:,5:].type(torch.BoolTensor).squeeze(0)\n",
    "        if(iou_mask.sum()==class_mask.shape[0]):\n",
    "            pos_class=raw_pred[iou_mask.T,:][:,5:][class_mask].mean().item()\n",
    "            neg_class=raw_pred[iou_mask.T,:][:,5:][~class_mask].mean().item()\n",
    "        else:\n",
    "            pos_class=0\n",
    "            neg_class=0\n",
    "            \n",
    "        noobj_box=noobj_box[noobj_mask]\n",
    "        no_obj_conf=noobj_box.mean().item()\n",
    "        \n",
    "        raw_pred=raw_pred[iou_mask.T,:]\n",
    "        anchors=anchors[iou_mask.T,:]\n",
    "        offset=offset[iou_mask.T,:]\n",
    "        strd=strd[iou_mask.T,:]\n",
    "        \n",
    "        if(strd.shape[0]==sum(mask)):#this means that iou_mask failed and was all true, because max of zeros is true for all lenght of mask strd\n",
    "            targets[:,:,0:4]=targets[:,:,0:4]*inp_dim\n",
    "            targets=targets.squeeze(0)\n",
    "            if hyperparameters['iou_type']==(0,0,0):\n",
    "                targets[:,0:4]=util.transform_groundtruth(targets,anchors,offset,strd)\n",
    "                loss=util.yolo_loss(raw_pred,targets,noobj_box,mask,hyperparameters)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                raw_pred=util.transform(raw_pred.unsqueeze(0),anchors.unsqueeze(0),offset.unsqueeze(0),strd.unsqueeze(0)).squeeze(0)\n",
    "                loss=util.yolo_loss(raw_pred,targets,noobj_box,mask,hyperparameters)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            avg_conf=avg_conf+conf\n",
    "            avg_no_conf=avg_no_conf+no_obj_conf\n",
    "            avg_pos=avg_pos+pos_class\n",
    "            avg_neg=avg_neg+neg_class\n",
    "            total_loss=total_loss+loss.item()\n",
    "            avg_iou=avg_iou+iou\n",
    "            sys.stdout.write('\\rPgr:'+str(prg_counter/dataset_len*100*batch_size)+'%' ' L:'+ str(loss.item()))\n",
    "            sys.stdout.write(' IoU:' +str(iou)+' pob:'+str(conf)+ ' nob:'+str(no_obj_conf))\n",
    "            sys.stdout.write(' PCls:' +str(pos_class)+' ncls:'+str(neg_class))\n",
    "            sys.stdout.flush()\n",
    "            prg_counter=prg_counter+1\n",
    "            train_counter=train_counter+1\n",
    "        else:\n",
    "            print('missed')\n",
    "            print(strd.shape[0])\n",
    "            prg_counter=prg_counter+1\n",
    "        iou1=iou1.tolist()\n",
    "        iou_per_class= [0] * 80\n",
    "        averager_per_class=[1] * 80\n",
    "        for i,el in enumerate(iou1):\n",
    "            name=targets[i,5:].max(0)[1].cpu().detach().numpy()\n",
    "            iou_per_class[name]=iou_per_class[name]+el\n",
    "            averager_per_class[name]=averager_per_class[name]+1\n",
    "        for i in range(80):\n",
    "            if (iou_per_class[i]!=0):\n",
    "                if i<40:\n",
    "                    writer.add_scalar('Iou0/'+str(i), iou_per_class[i]/averager_per_class[i], train_counter)\n",
    "                else:\n",
    "                    writer.add_scalar('Iou1/'+str(i), iou_per_class[i]/averager_per_class[i], train_counter)\n",
    "        writer.add_scalar('AvLoss/train', total_loss/train_counter, train_counter)\n",
    "\n",
    "        \n",
    "        writer.add_scalar('AvIoU/train', avg_iou/train_counter, train_counter)\n",
    "\n",
    "        writer.add_scalar('AvPConf/train', avg_conf/train_counter, train_counter)\n",
    "        \n",
    "        writer.add_scalar('AvNConf/train', avg_no_conf/train_counter, train_counter)\n",
    "        \n",
    "        writer.add_scalar('AvClass/train', avg_pos/train_counter, train_counter)\n",
    "        \n",
    "        writer.add_scalar('AvNClass/train', avg_neg/train_counter, train_counter)\n",
    "        \n",
    "        del loss, raw_pred, targets, true_pred, images,iou,noobj_box,conf,iou1\n",
    "        torch.cuda.empty_cache()\n",
    "    if misses>0:\n",
    "        break\n",
    "#     torch.save(model.state_dict(), PATH)\n",
    "#     writer.add_scalar('Loss/train', total_loss/train_counter, e)\n",
    "#     writer.add_scalar('AIoU/train', avg_iou/train_counter, e)\n",
    "#     writer.add_scalar('PConf/train', avg_conf/train_counter, e)\n",
    "#     writer.add_scalar('NConf/train', avg_no_conf/train_counter, e)\n",
    "#     writer.add_scalar('PClass/train', avg_pos/train_counter, e)\n",
    "#     writer.add_scalar('NClass/train', avg_neg/train_counter, e)\n",
    "    print('\\ntotal number of misses is ' + str(misses))\n",
    "    print('\\n total average loss is '+str(total_loss/train_counter))\n",
    "    print('\\n total average iou is '+str(avg_iou/train_counter))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        iou1=torch.diag(util.bbox_iou(util.get_abs_coord(true_pred[iou_mask.T,:].unsqueeze(-3)),util.transpose_target(get_abs_coord(targets)*inp_dim),hyperparameters['iou_type']))\n",
    "        iou=iou1.mean().item()\n",
    "        noobj_box=raw_pred[:,:,4:5].clone()\n",
    "        noobj_box=helper.uncollapse(noobj_box,mask)\n",
    "        noobj_mask=helper.uncollapse(noobj_mask.T.unsqueeze(-1),mask)\n",
    "        \n",
    "        \n",
    "        conf=raw_pred[iou_mask.T,:][:,4:5].mean().item()\n",
    "        class_mask=targets[:,:,5:].type(torch.BoolTensor).squeeze(0)\n",
    "        if(iou_mask.sum()==class_mask.shape[0]):\n",
    "            pos_class=raw_pred[iou_mask.T,:][:,5:][class_mask].mean().item()\n",
    "            neg_class=raw_pred[iou_mask.T,:][:,5:][~class_mask].mean().item()\n",
    "        else:\n",
    "            pos_class=0\n",
    "            neg_class=0\n",
    "            \n",
    "        noobj_box=noobj_box[noobj_mask]\n",
    "        no_obj_conf=noobj_box.mean().item()\n",
    "        \n",
    "        raw_pred=raw_pred[iou_mask.T,:]\n",
    "        anchors=anchors[iou_mask.T,:]\n",
    "        offset=offset[iou_mask.T,:]\n",
    "        strd=strd[iou_mask.T,:]\n",
    "        \n",
    "        if(strd.shape[0]==sum(mask)):#this means that iou_mask failed and was all true, because max of zeros is true for all lenght of mask strd\n",
    "            targets[:,:,0:4]=targets[:,:,0:4]*inp_dim\n",
    "            targets=targets.squeeze(0)\n",
    "            if hyperparameters['iou_type']==(0,0,0):\n",
    "                targets[:,0:4]=util.transform_groundtruth(targets,anchors,offset,strd)\n",
    "                loss=util.yolo_loss(raw_pred,targets,noobj_box,mask,hyperparameters)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                raw_pred=util.transform(raw_pred.unsqueeze(0),anchors.unsqueeze(0),offset.unsqueeze(0),strd.unsqueeze(0)).squeeze(0)\n",
    "                loss=util.yolo_loss(raw_pred,targets,noobj_box,mask,hyperparameters)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            avg_conf=avg_conf+conf\n",
    "            avg_no_conf=avg_no_conf+no_obj_conf\n",
    "            avg_pos=avg_pos+pos_class\n",
    "            avg_neg=avg_neg+neg_class\n",
    "            total_loss=total_loss+loss.item()\n",
    "            avg_iou=avg_iou+iou\n",
    "            sys.stdout.write('\\rPgr:'+str(prg_counter/dataset_len*100*batch_size)+'%' ' L:'+ str(loss.item()))\n",
    "            sys.stdout.write(' IoU:' +str(iou)+' pob:'+str(conf)+ ' nob:'+str(no_obj_conf))\n",
    "            sys.stdout.write(' PCls:' +str(pos_class)+' ncls:'+str(neg_class))\n",
    "            sys.stdout.flush()\n",
    "            prg_counter=prg_counter+1\n",
    "            train_counter=train_counter+1\n",
    "        else:\n",
    "            print('missed')\n",
    "            print(strd.shape[0])\n",
    "            prg_counter=prg_counter+1\n",
    "        iou1=iou1.tolist()\n",
    "        iou_per_class= [0] * 80\n",
    "        averager_per_class=[1] * 80\n",
    "        for i,el in enumerate(iou1):\n",
    "            name=targets[i,5:].max(0)[1].cpu().detach().numpy()\n",
    "            iou_per_class[name]=iou_per_class[name]+el\n",
    "            averager_per_class[name]=averager_per_class[name]+1\n",
    "        for i in range(80):\n",
    "            if (iou_per_class[i]!=0):\n",
    "                if i<40:\n",
    "                    writer.add_scalar('Iou0/'+str(i), iou_per_class[i]/averager_per_class[i], train_counter)\n",
    "                else:\n",
    "                    writer.add_scalar('Iou1/'+str(i), iou_per_class[i]/averager_per_class[i], train_counter)\n",
    "        writer.add_scalar('AvLoss/train', total_loss/train_counter, train_counter)\n",
    "\n",
    "        \n",
    "        writer.add_scalar('AvIoU/train', avg_iou/train_counter, train_counter)\n",
    "\n",
    "        writer.add_scalar('AvPConf/train', avg_conf/train_counter, train_counter)\n",
    "        \n",
    "        writer.add_scalar('AvNConf/train', avg_no_conf/train_counter, train_counter)\n",
    "        \n",
    "        writer.add_scalar('AvClass/train', avg_pos/train_counter, train_counter)\n",
    "        \n",
    "        writer.add_scalar('AvNClass/train', avg_neg/train_counter, train_counter)\n",
    "        \n",
    "        del loss, raw_pred, targets, true_pred, images,iou,noobj_box,conf,iou1\n",
    "        torch.cuda.empty_cache()\n",
    "    if misses>0:\n",
    "        break\n",
    "#     torch.save(model.state_dict(), PATH)\n",
    "#     writer.add_scalar('Loss/train', total_loss/train_counter, e)\n",
    "#     writer.add_scalar('AIoU/train', avg_iou/train_counter, e)\n",
    "#     writer.add_scalar('PConf/train', avg_conf/train_counter, e)\n",
    "#     writer.add_scalar('NConf/train', avg_no_conf/train_counter, e)\n",
    "#     writer.add_scalar('PClass/train', avg_pos/train_counter, e)\n",
    "#     writer.add_scalar('NClass/train', avg_neg/train_counter, e)\n",
    "    print('\\ntotal number of misses is ' + str(misses))\n",
    "    print('\\n total average loss is '+str(total_loss/train_counter))\n",
    "    print('\\n total average iou is '+str(avg_iou/train_counter))\n",
    "iou=bbox_iou(get_abs_coord(pred[:,0:4].unsqueeze(0)),get_abs_coord(targets[:,0:4].unsqueeze(0)),(1,0,0))\n",
    "print(iou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a=torch.tensor([0.93,0.35])\n",
    "print(torch.softmax(a,dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=torch.tensor([[[1,2],[3,4]]])\n",
    "print(test.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mask)\n",
    "\n",
    "idf=torch.stack([targets[:i,5:].sum(axis=0) for i in mask],dim=0)\n",
    "idf[idf>1]=1\n",
    "\n",
    "print(idf.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf=torch.tensor([1/mask[i] for i in range(len(mask)) for j in range(mask[i])]).cuda()\n",
    "obj_idf=hyperparameters['idf_weights']\n",
    "print(obj_idf)\n",
    "classes=targets[:,5:].max(1)[1]\n",
    "print(classes.tolist())\n",
    "print(obj_idf['obj_idf'][classes.tolist()])\n",
    "idf=np.array(obj_idf['obj_idf'][classes.tolist()])\n",
    "idf=torch.tensor(idf,device='cuda')\n",
    "idf=-torch.log(idf)\n",
    "\n",
    "tfidf=tf*idf\n",
    "tfidf=torch.softmax(tfidf,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets2,anchors,offset,strd,mask=helper.collapse_boxes(targets,pw_ph,cx_cy,stride)\n",
    "transformed_output=true_pred\n",
    "targets=targets\n",
    "offset=offset\n",
    "strd=strd\n",
    "mask=mask\n",
    "inp_dim\n",
    "'''\n",
    "this function takes the transformed_output and\n",
    "the target box in respect to the resized image size\n",
    "and returns a mask which can be applied to select the \n",
    "best raw input,anchors and cx_cy_offset\n",
    "and the noobj_mask for the negatives\n",
    "targets is a list\n",
    "'''\n",
    "#first transpose the centered normalised target coords\n",
    "centered_target=transpose_target(targets)[:,:,0:2]\n",
    "#multiply by inp_dim then devide by stride to get the relative grid size coordinates, floor the result to get the corresponding cell\n",
    "centered_target=torch.floor(centered_target*inp_dim/strd)\n",
    "#create a mask to find where the gt falls into which gridcell in the grid coordinate system\n",
    "fall_into_mask=centered_target==offset\n",
    "fall_into_mask=fall_into_mask[:,:,0]&fall_into_mask[:,:,1]\n",
    "#     fall_into_mask= ~fall_into_mask\n",
    "#create a copy of the transformed output\n",
    "best_bboxes=transformed_output.clone()\n",
    "#apply reverse mask to copy in order to zero all other bbox locations\n",
    "best_bboxes[~fall_into_mask]=0   \n",
    "#transform the copy to xmin,xmax,ymin,ymax\n",
    "best_responsible_coord=get_abs_coord(best_bboxes)\n",
    "targets=transpose_target(get_abs_coord(targets))*inp_dim\n",
    "#calculate best iou and mask\n",
    "responsible_iou=bbox_iou(best_responsible_coord,targets,True)\n",
    "\n",
    "responsible_iou[responsible_iou.ne(responsible_iou)] = 0\n",
    "responsible_mask=responsible_iou.max(dim=0)[0] == responsible_iou\n",
    "\n",
    "print(responsible_mask.shape)\n",
    "\n",
    "abs_coord=get_abs_coord(transformed_output)\n",
    "iou=bbox_iou(abs_coord,targets,True)\n",
    "iou[iou.ne(iou)] = 0\n",
    "ignore_mask=0.5<=iou\n",
    "inverted_mask=iou.max(dim=0)[0] != iou\n",
    "noobj_mask=~same_picture_mask(responsible_mask.clone()|ignore_mask,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(responsible_mask)\n",
    "if(responsible_mask.sum()>sum(mask)):\n",
    "    print('jello')\n",
    "    responsible_mask1=correct_iou_mask(responsible_mask,fall_into_mask)\n",
    "print(responsible_mask1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.randint(0, 9, (1,)) == torch.arange(9)\n",
    "a=a.repeat(5)\n",
    "a=a.repeat(2,1)\n",
    "print(a)\n",
    "print(a.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters={'lr':0.01,'batch_size':16,'weight_decay':0.001,'optimizer':'sgd','alpha':0.5,'gamma':2,'iou_ignore_thresh':0.5,'tfidf':True,'reduction':'sum'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_mask=(responsible_mask.sum(axis=0)==responsible_mask.sum(axis=0).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responsible_mask[:,le_mask]=(responsible_mask[:,le_mask]&fall_into_mask[le_mask,:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(le_mask)\n",
    "print(fall_into_mask[le_mask,:].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([1,2,3,4,5,6,6,6])\n",
    "indices=(((a==a.max())==True).nonzero())\n",
    "for ind in indices:\n",
    "    print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import timeit\n",
    "from dataset import *\n",
    "import torchvision.ops.boxes as nms_box\n",
    "import helper as helper\n",
    "from utils import *\n",
    "from BoundingBox import BoundingBox\n",
    "from BoundingBoxes import BoundingBoxes\n",
    "\n",
    "\n",
    "net = Darknet(\"../cfg/yolov3.cfg\")\n",
    "inp_dim=net.inp_dim\n",
    "pw_ph=net.pw_ph\n",
    "cx_cy=net.cx_cy\n",
    "stride=net.stride\n",
    "\n",
    "start_time = time.time()\n",
    "'''\n",
    "when loading weights from dataparallel model then, you first need to instatiate the dataparallel model \n",
    "if you start fresh then first model.load_weights and then make it parallel\n",
    "'''\n",
    "try:\n",
    "    PATH = '../pth/pretrained32_precomp_obj_soft.pth'\n",
    "    weights = torch.load(PATH)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(net)\n",
    "    else:\n",
    "        model=net\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    \n",
    "    model.load_state_dict(weights)\n",
    "    model.eval()\n",
    "except FileNotFoundError: \n",
    "    net.load_weights(\"../yolov3.weights\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "      print(\"Using \", torch.cuda.device_count(), \"GPUs!\")\n",
    "      model = nn.DataParallel(net)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('testing with '+ PATH +'\\n')\n",
    "transformed_dataset=Coco(partition='val',\n",
    "                                           transform=transforms.Compose([\n",
    "                                            ResizeToTensor(inp_dim)\n",
    "                                           ]))\n",
    "\n",
    "\n",
    "\n",
    "dataset_len=(len(transformed_dataset))\n",
    "print('Length of dataset is '+ str(dataset_len)+'\\n')\n",
    "batch_size=14\n",
    "\n",
    "dataloader = DataLoader(transformed_dataset, batch_size=batch_size,\n",
    "                        shuffle=False,collate_fn=helper.my_collate, num_workers=4)\n",
    "\n",
    "true_pos=0\n",
    "false_pos=0\n",
    "counter=0\n",
    "iou_threshold=0.5\n",
    "confidence=0.01\n",
    "recall_counter=0\n",
    "max_detections=None\n",
    "prg_counter=0\n",
    "for images,targets,img_name in dataloader:\n",
    "    inp=images.cuda()\n",
    "    raw_pred = model(inp, torch.cuda.is_available())\n",
    "    targets,anchors,offset,strd,mask=helper.collapse_boxes(targets,pw_ph,cx_cy,stride)\n",
    "    raw_pred=raw_pred.to(device='cuda')\n",
    "    true_pred=util.transform(raw_pred.clone(),pw_ph,cx_cy,stride)\n",
    "    \n",
    "#     classes=true_pred[:,:,5:].max(2)[0]\n",
    "    objectness=true_pred[:,:,4]\n",
    "    \n",
    "    sorted_pred=torch.sort(objectness,descending=True)\n",
    "    pred_mask=sorted_pred[0]>confidence\n",
    "    indices=[(sorted_pred[1][e,:][pred_mask[e,:]]) for e in range(pred_mask.shape[0])]\n",
    "    pred_final=[true_pred[i,indices[i],:] for i in range(len(indices))]\n",
    "    \n",
    "    pred_final_coord=[util.get_abs_coord(pred_final[i].unsqueeze(-2)) for i in range(len(pred_final))]\n",
    "    indices=[nms_box.nms(pred_final_coord[i][0],pred_final[i][:,4],iou_threshold) for i in range(len(pred_final))]\n",
    "    pred_final=[pred_final[i][indices[i],:] for i in range(len(pred_final))]\n",
    "#     pred_final[:,0:4]=pred_final[:,0:4]/inp_dim\n",
    "    helper.write_pred(img_name,pred_final,inp_dim,max_detections)\n",
    "    sys.stdout.write('\\rPgr:'+str(prg_counter/dataset_len*100*batch_size)+'%')\n",
    "    prg_counter=prg_counter+1\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "# Read txt files containing bounding boxes (ground truth and detections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darknet import *\n",
    "import darknet as dn\n",
    "import util as util\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import timeit\n",
    "from dataset import *\n",
    "import torchvision.ops.boxes as nms_box\n",
    "import helper as helper\n",
    "from utils import *\n",
    "from BoundingBox import BoundingBox\n",
    "from BoundingBoxes import BoundingBoxes\n",
    "# boundingboxes = helper.getBoundingBoxes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluator import *\n",
    "from utils import *\n",
    "from BoundingBox import BoundingBox\n",
    "\n",
    "from BoundingBoxes import BoundingBoxes\n",
    "\n",
    "\n",
    "boundingboxes = helper.getBoundingBoxes()\n",
    "evaluator = Evaluator()\n",
    "\n",
    "iou=0.5\n",
    "MMap=0\n",
    "while iou<1:\n",
    "    metricsPerClass = evaluator.GetPascalVOCMetrics(boundingboxes, IOUThreshold=iou)\n",
    "#     print(\"Average precision values per class:\\n\")\n",
    "    # Loop through classes to obtain their metrics\n",
    "    mAP=0\n",
    "    counter=0\n",
    "    for mc in metricsPerClass:\n",
    "        # Get metric values per each class\n",
    "        c = mc['class']\n",
    "        precision = mc['precision']\n",
    "        recall = mc['recall']\n",
    "        average_precision = mc['AP']\n",
    "        ipre = mc['interpolated precision']\n",
    "        irec = mc['interpolated recall']\n",
    "        # Print AP per class\n",
    "        mAP=average_precision+mAP\n",
    "#         print('%s: %f' % (c, average_precision))\n",
    "    MMap=MMap+mAP/80\n",
    "    iou=iou+0.05\n",
    "    print('\\nCOCO map is:',MMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.6403413112473646\n",
    "0.6503946905414258\n",
    "for mc in metricsPerClass:\n",
    "    c = mc['class']\n",
    "    average_precision = mc['AP']\n",
    "    print('%s: %f' % (c, average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0,0,0)==(0,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%s: %f' % (c, average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluator import *\n",
    "evaluator = Evaluator()\n",
    "metricsPerClass = evaluator.GetPascalVOCMetrics(boundingboxes, IOUThreshold=0.5)\n",
    "print(\"Average precision values per class:\\n\")\n",
    "# Loop through classes to obtain their metrics\n",
    "mAP=0\n",
    "counter=0\n",
    "for mc in metricsPerClass:\n",
    "    # Get metric values per each class\n",
    "    c = mc['class']\n",
    "    precision = mc['precision']\n",
    "    recall = mc['recall']\n",
    "    average_precision = mc['AP']\n",
    "    ipre = mc['interpolated precision']\n",
    "    irec = mc['interpolated recall']\n",
    "    # Print AP per class\n",
    "    mAP=average_precision+mAP\n",
    "    print('%s: %f' % (c, average_precision))\n",
    "\n",
    "print('map is:',mAP/80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.07290217209136615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "coord=pred_final[:,:4].cpu().detach().numpy()\n",
    "conf=pred_final[:,4:5].cpu().detach().numpy()\n",
    "mat=np.hstack((conf,coord))\n",
    "\n",
    "classes=pred_final[:,5:].max(1)[1].cpu().detach().numpy()\n",
    "classes=np.array([classes]).T\n",
    "\n",
    "mat=np.hstack((classes,mat))\n",
    "mat=np.array(mat)\n",
    "\n",
    "df=pd.DataFrame(mat,index=None,columns=None)\n",
    "df[0]=df[0].apply(lambda x: int(x))\n",
    "\n",
    "df.to_csv('test.txt',sep=' ',header=False,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('test.txt',mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.tensor([1,2,2,3,4,2,3,1,4])\n",
    "print(a.max(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image=(inp).squeeze(0)\n",
    "image=np.array(image.cpu())\n",
    "print(image.shape)\n",
    "image =  image[:,:,::-1].transpose((1,2,0))\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "all_files = glob.glob('plots/' + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in sorted(all_files):\n",
    "    print(filename)\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=1, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../pointer.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[:None]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# gca stands for 'get current axis'\n",
    "\n",
    "title_list=['AIoU_train','Loss_train','NClass_train','NConf_train','PClass','PConf']\n",
    "\n",
    "fig = plt.figure(figsize=(30, 10))\n",
    "fig.suptitle('KL for xy loss')\n",
    "fig.subplots_adjust(hspace=0.3, wspace=-.6)\n",
    "colors = ['#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c']\n",
    "i=2\n",
    "k=0\n",
    "while i <18:\n",
    "    ax = fig.add_subplot(2, 9, i)\n",
    "    frame.plot(x =1 , y = i,ax=ax,legend=False)\n",
    "    ax.set_title(title_list[k])\n",
    "    i=i+3\n",
    "    k=k+1\n",
    "plt.savefig('original.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=['class','xc','yc','w','h','filename'])\n",
    "current_dir='/mnt/data1/users/konsa15/workspace/notebooks/coco/labels/coco/yolo'\n",
    "os.chdir('/mnt/data1/users/konsa15/workspace/notebooks/coco/labels/coco/labels/val2017')\n",
    "print(os.getcwd())\n",
    "files = glob.glob(\"*.txt\")\n",
    "dataset_len=len(files)\n",
    "prg_counter=0\n",
    "print(dataset_len)\n",
    "for file in files:\n",
    "    with open(file) as f:\n",
    "        f=f.read()\n",
    "        box=pd.DataFrame([map(float,x.split()) for x in f.rstrip('\\n').split('\\n')],columns=['class','xc','yc','w','h'])\n",
    "        box['filename']=[file for x in f.rstrip('\\n').split('\\n')]\n",
    "        df = df.append(box, ignore_index = True)\n",
    "        \n",
    "    sys.stdout.write('\\rPgr:'+str(prg_counter/dataset_len*100)+'%')\n",
    "    prg_counter+=1\n",
    "\n",
    "print(df)\n",
    "obj_idf=(df['class'].value_counts(normalize=True).reset_index(name='obj_idf'))\n",
    "new_df=df.groupby('filename')['class'].value_counts().reset_index(name='count')\n",
    "img_idf=new_df['class'].value_counts(normalize=True).reset_index(name='img_idf')\n",
    "\n",
    "obj_idf['img_idf']=img_idf['img_idf']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['area']=df['w']*df['h']\n",
    "total_area=df['area'].sum()\n",
    "\n",
    "area_idf=df.groupby('class')['area'].sum().reset_index(name='area')\n",
    "print(area_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a=torch.ones(10)\n",
    "a=a.unsqueeze(1)\n",
    "a=torch.softmax(a,dim=0)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "\n",
    "from multiprocessing import Pool # for reading the CSVs faster\n",
    "\n",
    "def my_read_csv(filename):\n",
    "    try:\n",
    "        f=open(filename).read()\n",
    "        box=pd.DataFrame([map(float,x.split()) for x in f.rstrip('\\n').split('\\n')],columns=['class','xc','yc','w','h'])\n",
    "        box['filename']=[filename for x in f.rstrip('\\n').split('\\n')]\n",
    "        return box\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "\n",
    "def load_csvs():\n",
    "    \"\"\"Reads and joins all our CSV files into one big dataframe.\n",
    "    We do it in parallel to make it faster, since otherwise it takes some time.\n",
    "    Idea from: https://stackoverflow.com/questions/36587211/easiest-way-to-read-csv-files-with-multiprocessing-in-pandas\n",
    "    \n",
    "    \"\"\"\n",
    "    # set up your pool\n",
    "    pool = Pool() \n",
    "    os.chdir('/mnt/data1/users/konsa15/workspace/notebooks/coco/labels/coco/labels/train2017')\n",
    "    print(os.getcwd())\n",
    "    files = os.listdir('.')\n",
    "    file_list = [filename for filename in files if filename.split('.')[1]=='txt']\n",
    "    print(len(file_list))\n",
    "    df_list = pool.map(my_read_csv, file_list)\n",
    "    # reduce the list of dataframes to a single dataframe\n",
    "    return pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=load_csvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df)\n",
    "obj_idf=(df['class'].value_counts(normalize=True).reset_index(name='obj_freq'))\n",
    "new_df=df.groupby('filename')['class'].value_counts().reset_index(name='count')\n",
    "img_idf=new_df['class'].value_counts(normalize=True).reset_index(name='img_freq')\n",
    "\n",
    "obj_idf['img_freq']=img_idf['img_freq']\n",
    "\n",
    "total_bins=df['class'].value_counts()\n",
    "print(total_bins)\n",
    "yc_idf=df.groupby('class')['yc'].sum()\n",
    "xc_idf=df.groupby('class')['xc'].sum()\n",
    "\n",
    "df['area']=df['w']*df['h']\n",
    "area_idf=df.groupby('class')['area'].sum()\n",
    "\n",
    "\n",
    "obj_idf['xc']=(xc_idf/total_bins)\n",
    "obj_idf['yc']=(yc_idf/total_bins)\n",
    "obj_idf['area']=(area_idf/total_bins)\n",
    "print(obj_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "idf=pd.read_csv('../idf.csv')\n",
    "print(idf['obj_freq'][[0,0,1,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test=obj_idf\n",
    "test.plot(x='xc',y='yc',kind='scatter')\n",
    "# fig1.savefig('corr_with_person_obj.png')\n",
    "test.plot(x='xc',y='obj_freq',kind='scatter')\n",
    "test.plot(x='yc',y='img_freq',kind='scatter')\n",
    "\n",
    "test.plot(x='xc',y='area',kind='scatter')\n",
    "test.plot(x='yc',y='area',kind='scatter')\n",
    "# fig2.savefig('corr_with_person_img.png')\n",
    "test.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "df = pd.DataFrame()\n",
    "files = glob.glob(\"../map/*.csv\")\n",
    "for file in files:\n",
    "    map_csv=pd.read_csv(file)\n",
    "    dat1 = pd.DataFrame({file.split('/')[2].split('.')[0]: map_csv['Value']})\n",
    "    df=pd.concat([df,dat1],axis=1)\n",
    "#     df.drop(columns=[\"\"])\n",
    "    df=df.dropna()\n",
    "\n",
    "df.to_csv('comparative_map.csv')\n",
    "df.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('comparative_map.csv')\n",
    "df=df.drop(columns=[\"index\"])\n",
    "fig=df.plot().get_figure()\n",
    "fig.savefig('comparative_map.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
